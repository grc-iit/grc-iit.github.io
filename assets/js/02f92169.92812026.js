"use strict";(self.webpackChunkgnosis=self.webpackChunkgnosis||[]).push([[7108],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>h});var i=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,i)}return a}function n(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,i,r=function(e,t){if(null==e)return{};var a,i,r={},s=Object.keys(e);for(i=0;i<s.length;i++)a=s[i],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(i=0;i<s.length;i++)a=s[i],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=i.createContext({}),c=function(e){var t=i.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):n(n({},t),e)),a},u=function(e){var t=c(e.components);return i.createElement(l.Provider,{value:t},e.children)},d="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},m=i.forwardRef((function(e,t){var a=e.components,r=e.mdxType,s=e.originalType,l=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),d=c(a),m=r,h=d["".concat(l,".").concat(m)]||d[m]||p[m]||s;return a?i.createElement(h,n(n({ref:t},u),{},{components:a})):i.createElement(h,n({ref:t},u))}));function h(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var s=a.length,n=new Array(s);n[0]=m;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o[d]="string"==typeof e?e:r,n[1]=o;for(var c=2;c<s;c++)n[c]=a[c];return i.createElement.apply(null,n)}return i.createElement.apply(null,a)}m.displayName="MDXCreateElement"},4673:(e,t,a)=>{a.r(t),a.d(t,{contentTitle:()=>o,default:()=>p,frontMatter:()=>n,metadata:()=>l,toc:()=>c});var i=a(7462),r=(a(7294),a(3905)),s=a(3161);const n={title:"DTIO: A Data Task I/O Runtime"},o=void 0,l={type:"mdx",permalink:"/research/projects/dtio",source:"@site/src/pages/research/projects/dtio.mdx",title:"DTIO: A Data Task I/O Runtime",description:"In partnership with Argonne National Laboratory, DTIO investigates the use of a task framework for unifying complex I/O stacks and providing features such as resilience, fault-tolerance, and task replay.",frontMatter:{title:"DTIO: A Data Task I/O Runtime"}},c=[{value:"Introduction",id:"introduction",level:2},{value:"Methodology",id:"methodology",level:2},{value:"Relaxing POSIX consistency to improve scalability",id:"relaxing-posix-consistency-to-improve-scalability",level:2},{value:"Scheduling constraints to improve resource utilization",id:"scheduling-constraints-to-improve-resource-utilization",level:2},{value:"Task provenance to improve fault tolerance",id:"task-provenance-to-improve-fault-tolerance",level:2}],u={toc:c},d="wrapper";function p(e){let{components:t,...n}=e;return(0,r.kt)(d,(0,i.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(7561).Z,width:"140"})),(0,r.kt)("h1",{id:"dtio-a-data-task-io-runtime"},"DTIO: A Data Task I/O Runtime"),(0,r.kt)(s.Z,{projectId:"dtio",mdxType:"ProjectBadges"}),(0,r.kt)("p",null,"In partnership with Argonne National Laboratory, DTIO investigates the use of a task framework for unifying complex I/O stacks and providing features such as resilience, fault-tolerance, and task replay."),(0,r.kt)("h2",{id:"introduction"},"Introduction"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"POSIX I/O has problems with scalability due to its strict internal metadata tracking, which requires RAW guarantees"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Insight"),": A task-based infrastructure gives several advantages over a batch-based infrastructure, which can also apply to I/O tasks"),(0,r.kt)("li",{parentName:"ul"},"Improved scalability via relaxation of POSIX consistency, which allows tasks to execute faster even if it disobeys strict ordering"),(0,r.kt)("li",{parentName:"ul"},"Improved resource utilization via constraint-based task scheduling, which allows tasks to consider load on an executor"),(0,r.kt)("li",{parentName:"ul"},"Improved fault-tolerance via task provenance, which allows replay of tasks in the event of a fault"),(0,r.kt)("li",{parentName:"ul"},"In addition, we aim to leverage hierarchical storage and computational storage techniques to provide an infrastructure that unifies and extends the current I/O stacks")),(0,r.kt)("h2",{id:"methodology"},"Methodology"),(0,r.kt)("center",null,(0,r.kt)("img",{src:a(9880).Z,width:"600",alt:"dtio architecture",title:"",class:""})),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"DTIO Client creates the task and places on a worker, and DTIO servers execute the tasks"),(0,r.kt)("li",{parentName:"ul"},"Composition is generally expected to be done alongside the application (client-side)"),(0,r.kt)("li",{parentName:"ul"},"For scheduling, centralized deployments can collate information from different apps, while multiprocess deployments scale better"),(0,r.kt)("li",{parentName:"ul"},"For workers, dedicated execution resources are the best choice")),(0,r.kt)("h2",{id:"relaxing-posix-consistency-to-improve-scalability"},"Relaxing POSIX consistency to improve scalability"),(0,r.kt)("center",null,(0,r.kt)("img",{src:a(9958).Z,width:"600",alt:"POSIX scalability",title:"",class:""})),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"POSIX metadata and consistency guarantees cause performance drops for IOR at scale."),(0,r.kt)("li",{parentName:"ul"},"Relaxation of POSIX consistency in a task system can come in a few ways."),(0,r.kt)("li",{parentName:"ul"},"Delay when creating tasks, scheduling tasks, or executing tasks."),(0,r.kt)("li",{parentName:"ul"},"These ideas are often represented naturally with task queues, as queued tasks need not be dequeued immediately.")),(0,r.kt)("h2",{id:"scheduling-constraints-to-improve-resource-utilization"},"Scheduling constraints to improve resource utilization"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"To achieve improved resource utilization, tasks can be scheduled to workers depending on load."),(0,r.kt)("li",{parentName:"ul"},"Task Status can be unscheduled, scheduled, or completed."),(0,r.kt)("li",{parentName:"ul"},"A simple constraint: schedule a task to the executor which is currently running the fewest tasks."),(0,r.kt)("li",{parentName:"ul"},"More complex constraint: track the I/O size of tasks to each executor and schedule to the executor with the lowest I/O load.")),(0,r.kt)("h2",{id:"task-provenance-to-improve-fault-tolerance"},"Task provenance to improve fault tolerance"),(0,r.kt)("center",null,(0,r.kt)("img",{src:a(8973).Z,width:"600",alt:"Tasks as a record of control flow, with task replays visualized for write kernel and fault recovery",title:"",class:""})),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Tasks are a record of control flow, and therefore it is possible to use tasks in the event of a fault to restore the state of storage."),(0,r.kt)("li",{parentName:"ul"},"Best to store tasks in a separate database and maintain their status."),(0,r.kt)("li",{parentName:"ul"},"If a separate database is not desirable, workers can provide a record of task execution, though this necessitates a method of determining which worker has which task."),(0,r.kt)("li",{parentName:"ul"},"Statuses, alongside task timestamps, can permit task replay in the event of a fault."),(0,r.kt)("li",{parentName:"ul"},"Fault recovery may not need to replay writes, supposing they've already been persisted to disks."),(0,r.kt)("li",{parentName:"ul"},"Task replay also has other usecases outside of fault tolerance, such as generating I/O kernels or responsibility identification (blaming).")))}p.isMDXComponent=!0},3161:(e,t,a)=>{a.d(t,{Z:()=>n});var i=a(7294),r=a(6010),s=a(866);function n(e){let{addMargin:t=!0,projectId:a}=e;const{isOpenSource:n=!1,isOurs:o=!1}=(0,s.R)(a);return n||o?i.createElement("div",{className:(0,r.Z)(t&&"margin-bottom--md"),style:{lineHeight:1}},o&&i.createElement("span",{className:"badge badge--primary margin-horiz--xs"},"GRC-LED"),n&&i.createElement("span",{className:"badge badge--secondary margin-horiz--xs"},"OPEN SOURCE")):null}},866:(e,t,a)=>{a.d(t,{R:()=>s,Z:()=>r});const i=[{id:"coeus",name:"Coeus",title:"Coeus: Accelerating Scientific Insights Using Enriched Metadata",shortDescription:"In collaboration with Sandia and Oak Ridge National Laboratories, coeus investigate the use of an active storage system to calculate derived quantities and support complex queries on scientific data (simulation and observational) as well as optimizing data placement across the storage hierarchy, with awareness of the resource limitations, to better support the scientific discovery process.",link:"/research/projects/coeus",isFeatured:!0,isOurs:!0,researchStatus:"r&d",status:"active",type:"funded"},{id:"chronolog",name:"ChronoLog",title:"ChronoLog: A High-Performance Storage Infrastructure for Activity and Log Workloads",shortDescription:"HPC applications generate more data than storage systems can handle, and it is becoming increasingly important to store activity (log) data generated by people and applications. ChronoLog is a hierarchical, distributed log store that leverages physical time to achieve log ordering and reduce contention while utilizing storage tiers to elastically scale the log capacity.",link:"/research/projects/chronolog",isFeatured:!0,isOpenSource:!0,isOurs:!0,researchStatus:"testing",status:"active",type:"funded"},{id:"iris",name:"IRIS",title:"IRIS: I/O Redirection Via Integrated Storage",shortDescription:"Various storage solutions exist and require specialized APIs and data models in order to use, which binds developers, applications, and entire computing facilities to using certain interfaces. Each storage system is designed and optimized for certain applications but does not perform well for others. IRIS is a unified storage access system that bridges the semantic gap between filesystems and object stores.",link:"/research/projects/iris",isFeatured:!1,isOpenSource:!0,isOurs:!0,researchStatus:"testing",status:"active",type:"funded"},{id:"hermes",name:"Hermes",title:"Hermes: Extending the HDF Library to Support Intelligent I/O Buffering for Deep Memory and Storage Hierarchy System",shortDescription:"To reduce the I/O bottleneck, complex storage hierarchies have been introduced. However, managing this complexity should not be left to application developers. Hermes is a middeware library that automatically manages buffering in heterogeneous storage environments.",link:"/research/projects/hermes",isFeatured:!0,isOpenSource:!0,isOurs:!0,researchStatus:"ready",status:"active",type:"funded"},{id:"labios",name:"Labios",title:"LABIOS: A Distributed Label-Based I/O System",shortDescription:"HPC and Big Data environments have diverged over the years, resulting in diverging and even conflicting I/O requirements. Labios aims to address the challenges vital to HPC + Big Data Convergence",link:"/research/projects/labios",isFeatured:!1,isOurs:!0,researchStatus:"r&d",status:"active",type:"funded"},{id:"dtio",name:"DTIO",title:"DTIO: A Data Task I/O Runtime",shortDescription:"In partnership with Argonne National Laboratory, DTIO investigates the use of a task framework for unifying complex I/O stacks and providing features such as resilience, fault-tolerance, and task replay.",link:"/research/projects/dtio",isFeatured:!1,isOurs:!0,researchStatus:"testing",status:"active",type:"funded"},{id:"viper",name:"Viper",title:"Viper: A High-Performance I/O Framework for Transferring Deep Neural Network Models",shortDescription:"Within a DL workflow, exchanging DNN models through PFS may result in  high model update latency and discovery latency. Moreover, model update frequency affects both training and inference performance. Viper is an I/O framework aiming to accelerate model discovery and delivery, and to find an optimal model checkpoint schedule to balance the trade-off.",link:"/research/projects/viper",isFeatured:!1,isOurs:!0,researchStatus:"r&d",status:"active",type:"funded"},{id:"dayu",name:"DaYu",title:"DaYu: Optimizing Workflow Performance by Elucidating Semantic Data Flow",shortDescription:"Nowadays, distributed scientific workflows encounter challenges in data movement through storage systems. DaYu, by capturing the mapping of data objects to I/O operations, can uncover new insights for optimizing workflow data movement.",link:"/research/projects/dayu",isFeatured:!1,isOpenSource:!0,isOurs:!0,researchStatus:"testing",status:"active",type:"funded"},{id:"wisio",name:"WisIO",title:"WisIO: Automated I/O Bottleneck Detection via Multi-Perspective Views for HPC Workloads",shortDescription:"Explore WisIO, an automated I/O bottleneck detection tool with multi-perspective views for I/O trace data analysis. Overcoming large-scale I/O challenges, WisIO utilizes distributed computing and an extensible rule engine for tailored solutions. Elevate your I/O analysis in HPC environments with WisIO.",link:"/research/projects/wisio",isFeatured:!1,isOpenSource:!1,isOurs:!0,researchStatus:"r&d",status:"active",type:"student"}],r=i;function s(e){return i.find((t=>t.id===e))}},9880:(e,t,a)=>{a.d(t,{Z:()=>i});const i=a.p+"assets/images/dtio-arch-460cf96e637bc6f22268e02f6c172a74.png"},7561:(e,t,a)=>{a.d(t,{Z:()=>i});const i=a.p+"assets/images/logo-9e75d71cd7192feeb44267194a9459f7.png"},9958:(e,t,a)=>{a.d(t,{Z:()=>i});const i=a.p+"assets/images/posix-scalability-d984b8e3aa6829e17418344f404b1977.png"},8973:(e,t,a)=>{a.d(t,{Z:()=>i});const i=a.p+"assets/images/queue-visualization-e59b05701120b112df204b77a842b8ab.png"}}]);