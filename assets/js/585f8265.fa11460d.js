"use strict";(self.webpackChunkgnosis=self.webpackChunkgnosis||[]).push([[3839],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>m});var r=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},i=Object.keys(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var s=r.createContext({}),c=function(e){var t=r.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},d=function(e){var t=c(e.components);return r.createElement(s.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},g=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,i=e.originalType,s=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),p=c(a),g=n,m=p["".concat(s,".").concat(g)]||p[g]||u[g]||i;return a?r.createElement(m,l(l({ref:t},d),{},{components:a})):r.createElement(m,l({ref:t},d))}));function m(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=a.length,l=new Array(i);l[0]=g;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o[p]="string"==typeof e?e:n,l[1]=o;for(var c=2;c<i;c++)l[c]=a[c];return r.createElement.apply(null,l)}return r.createElement.apply(null,a)}g.displayName="MDXCreateElement"},1273:(e,t,a)=>{a.r(t),a.d(t,{contentTitle:()=>o,default:()=>u,frontMatter:()=>l,metadata:()=>s,toc:()=>c});var r=a(7462),n=(a(7294),a(3905)),i=a(3161);const l={title:"Chronolog: A High-Performance Storage Infrastructure for Activity and Log Workloads"},o=void 0,s={type:"mdx",permalink:"/research/projects/chronolog",source:"@site/src/pages/research/projects/chronolog.mdx",title:"Chronolog: A High-Performance Storage Infrastructure for Activity and Log Workloads",description:"HPC applications generate more data than storage systems can handle, and it is becoming increasingly important to store",frontMatter:{title:"Chronolog: A High-Performance Storage Infrastructure for Activity and Log Workloads"}},c=[{value:"Background",id:"background",level:2},{value:"Synopsis",id:"synopsis",level:2},{value:"Workloads &amp; Applications",id:"workloads--applications",level:2},{value:"Challenges",id:"challenges",level:2},{value:"Key Insights &amp; Project Impact",id:"key-insights--project-impact",level:2},{value:"Research Contributions",id:"research-contributions",level:2},{value:"Software Contributions",id:"software-contributions",level:2},{value:"Design Requirements",id:"design-requirements",level:2},{value:"Architecture",id:"architecture",level:2},{value:"Data Model &amp; API",id:"data-model--api",level:2},{value:"Design Details",id:"design-details",level:2},{value:"Features &amp; Operations",id:"features--operations",level:2},{value:"Log Auto-Tiering",id:"log-auto-tiering",level:2},{value:"Log Querying &amp; Range Retrieval",id:"log-querying--range-retrieval",level:2},{value:"Evaluation Results",id:"evaluation-results",level:2},{value:"Publications",id:"publications",level:2},{value:"Members",id:"members",level:2},{value:"Collaborators",id:"collaborators",level:2},{value:"Sponsor",id:"sponsor",level:2}],d={toc:c},p="wrapper";function u(e){let{components:t,...l}=e;return(0,n.kt)(p,(0,r.Z)({},d,l,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("p",null,(0,n.kt)("img",{src:a(3933).Z,width:"200"})),(0,n.kt)("h1",{id:"chronolog-a-high-performance-storage-infrastructure-for-activity-and-log-workloads"},"Chronolog: A High-Performance Storage Infrastructure for Activity and Log Workloads"),(0,n.kt)(i.Z,{projectId:"chronolog",mdxType:"ProjectBadges"}),(0,n.kt)("p",null,"HPC applications generate more data than storage systems can handle, and it is becoming increasingly important to store\nactivity (log) data generated by people and applications. ChronoLog is a hierarchical, distributed log store that leverages\nphysical time to achieve log ordering and reduce contention while utilizing storage tiers to elastically scale the log capacity."),(0,n.kt)("h2",{id:"background"},"Background"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Modern application domains in science and engineering, from astrophysics to web services and financial computations\ngenerate massive amounts of data at unprecedented rates (reaching up to 7 TB/s).")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"The promise of future data utility and the low cost of data storage caused by recent hardware innovations (less than\n$0.02/GB) is driving this data explosion resulting in widespread data hoarding from researchers and engineers."))),(0,n.kt)("p",null,"This trend stresses existing storage systems past their capability and exceeds the capacity of even the largest computing systems,\nand it is becoming increasingly important to store and process activity (log) data generated by people and applications. Including:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Scientific Applications"),(0,n.kt)("li",{parentName:"ul"},"Internet Companies"),(0,n.kt)("li",{parentName:"ul"},"Financial Applications"),(0,n.kt)("li",{parentName:"ul"},"Microservices and Containers"),(0,n.kt)("li",{parentName:"ul"},"IoT"),(0,n.kt)("li",{parentName:"ul"},"Task-based Computing")),(0,n.kt)("p",null,"Distributed log stores require:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Total Ordering"),(0,n.kt)("li",{parentName:"ul"},"High Concurrency and Parallelism"),(0,n.kt)("li",{parentName:"ul"},"Capacity Scaling")),(0,n.kt)("h2",{id:"synopsis"},"Synopsis"),(0,n.kt)("p",null,"This project will design and implement ChronoLog, a distributed and tiered shared log storage ecosystem. ChronoLog uses physical time to\ndistribute log entries while providing total log ordering. It also utilizes multiple storage tiers to elastically scale the log capacity\n(i.e., auto-tiering). ChronoLog will serve as a foundation for developing scalable new plugins, including a SQL-like query engine for\nlog data, a streaming processor leveraging the time-based data distribution, a log-based key-value store, and a log-based TensorFlow module."),(0,n.kt)("h2",{id:"workloads--applications"},"Workloads & Applications"),(0,n.kt)("p",null,"Modern applications spanning from Edge to High Performance Computing (HPC) systems, produce and process log data and create a plethora\nof workload characteristics that rely on a common storage model:"),(0,n.kt)("center",null,(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"The Distributed Shared Log"),":"),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Distributed Shared Log",src:a(2986).Z,width:"726",height:"296"}))),(0,n.kt)("h2",{id:"challenges"},"Challenges"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Ensuring total ordering of log data in a distributed environment is expensive"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Single point of contention (tail of the log)"),(0,n.kt)("li",{parentName:"ul"},"High cost of synchronization"),(0,n.kt)("li",{parentName:"ul"},"Centralized sequencers"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Efficiently scale log capacity"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Time- or space-based data retention policies"),(0,n.kt)("li",{parentName:"ul"},"Add servers offline and rebalance cluster"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Highly concurrent log operations by multiple clients"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Single-writer-multiple-readers (SWMR) data access model"),(0,n.kt)("li",{parentName:"ul"},"Limited operation concurrency"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"I/O parallelism"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Application-centric implicit parallel model (e.g., consumer groups)"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Partial data retrieval (log querying)"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Expensive auxiliary indices"),(0,n.kt)("li",{parentName:"ul"},"Metadata look-ups"),(0,n.kt)("li",{parentName:"ul"},"Client-side epochs")))),(0,n.kt)("table",null,(0,n.kt)("thead",{parentName:"table"},(0,n.kt)("tr",{parentName:"thead"},(0,n.kt)("th",{parentName:"tr",align:null},(0,n.kt)("strong",{parentName:"th"},"Features")),(0,n.kt)("th",{parentName:"tr",align:null},(0,n.kt)("strong",{parentName:"th"},"Bookkeeper Kafka/DLog")),(0,n.kt)("th",{parentName:"tr",align:null},(0,n.kt)("strong",{parentName:"th"},"Corfu SloG/ZLog")),(0,n.kt)("th",{parentName:"tr",align:null},(0,n.kt)("strong",{parentName:"th"},"ChronoLog")))),(0,n.kt)("tbody",{parentName:"table"},(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Locating the log-tail"),(0,n.kt)("td",{parentName:"tr",align:null},"MDM lookup (locking)"),(0,n.kt)("td",{parentName:"tr",align:null},"Sequencer (locking)"),(0,n.kt)("td",{parentName:"tr",align:null},"MDM lookup (lock-free)")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"I/O isolation"),(0,n.kt)("td",{parentName:"tr",align:null},"Yes"),(0,n.kt)("td",{parentName:"tr",align:null},"No"),(0,n.kt)("td",{parentName:"tr",align:null},"Yes")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"I/O parallelism (readers-to-servers)"),(0,n.kt)("td",{parentName:"tr",align:null},"1-to-1"),(0,n.kt)("td",{parentName:"tr",align:null},"1-to-N"),(0,n.kt)("td",{parentName:"tr",align:null},"M-to-N (always)")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Storage elasticity (scaling capacity)"),(0,n.kt)("td",{parentName:"tr",align:null},"Only horizontal"),(0,n.kt)("td",{parentName:"tr",align:null},"No"),(0,n.kt)("td",{parentName:"tr",align:null},"Vertical and horizontal")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Log hot zones"),(0,n.kt)("td",{parentName:"tr",align:null},"Yes (active ledger)"),(0,n.kt)("td",{parentName:"tr",align:null},"No"),(0,n.kt)("td",{parentName:"tr",align:null},"No")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Log capacity"),(0,n.kt)("td",{parentName:"tr",align:null},"Data retention"),(0,n.kt)("td",{parentName:"tr",align:null},"Limited by # of SSDs"),(0,n.kt)("td",{parentName:"tr",align:null},"Infinite (auto-tiering)")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Operation parallelism"),(0,n.kt)("td",{parentName:"tr",align:null},"Only Read (implicit)"),(0,n.kt)("td",{parentName:"tr",align:null},"Write/Read"),(0,n.kt)("td",{parentName:"tr",align:null},"Write/Read")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Granularity of data distribution"),(0,n.kt)("td",{parentName:"tr",align:null},"Closed Ledgers (log-partition)"),(0,n.kt)("td",{parentName:"tr",align:null},"SSD page (set of entries)"),(0,n.kt)("td",{parentName:"tr",align:null},"Event (per entry)")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Log total ordering"),(0,n.kt)("td",{parentName:"tr",align:null},"No (only on partitions)"),(0,n.kt)("td",{parentName:"tr",align:null},"Yes (eventually)"),(0,n.kt)("td",{parentName:"tr",align:null},"Yes")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Log entry visibility"),(0,n.kt)("td",{parentName:"tr",align:null},"Immediate"),(0,n.kt)("td",{parentName:"tr",align:null},"End of epoch"),(0,n.kt)("td",{parentName:"tr",align:null},"Immediate")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Storage overhead per entry"),(0,n.kt)("td",{parentName:"tr",align:null},"Yes (2x)"),(0,n.kt)("td",{parentName:"tr",align:null},"No"),(0,n.kt)("td",{parentName:"tr",align:null},"No")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Tiered storage"),(0,n.kt)("td",{parentName:"tr",align:null},"No"),(0,n.kt)("td",{parentName:"tr",align:null},"No"),(0,n.kt)("td",{parentName:"tr",align:null},"Yes")))),(0,n.kt)("h2",{id:"key-insights--project-impact"},"Key Insights & Project Impact"),(0,n.kt)("h2",{id:"research-contributions"},"Research Contributions"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"How physical time can be used to distribute and order log data without the need for explicit synchronizations or centralized sequencing\noffering a high-performance and scalable shared log store with the ability to support efficient range data retrieval."),(0,n.kt)("li",{parentName:"ul"},"How multi-tiered storage can be used to scale the capacity of a log and offer tunable data access parallelism while maintaining I/O\nisolation and a highly concurrent access model supporting multiple-writers-multiple-readers (MWMR)."),(0,n.kt)("li",{parentName:"ul"},"How elastic storage semantics and dynamic resource provisioning can be used to achieve an efficient matching between I/O production and\nconsumption rates of conflicting workloads under a single system.")),(0,n.kt)("h2",{id:"software-contributions"},"Software Contributions"),(0,n.kt)("p",null,"ChronoLog will create a future-proof storage infrastructure targeting large-scale systems and applications."),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"The ChronoLog Core Library"),(0,n.kt)("li",{parentName:"ul"},"An in-memory lock-free distributed journal with the ability to persist data on flash storage to enable a fast distributed caching layer"),(0,n.kt)("li",{parentName:"ul"},"A new high-performance data streaming service specifically, but not limited, for HPC systems that uses MPI for job distribution and RPC\nover RDMA (or over RoCE) for communication"),(0,n.kt)("li",{parentName:"ul"},"A set of high-level interfaces for I/O")),(0,n.kt)("center",null,(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Chronolog Software",src:a(6754).Z,width:"1600",height:"666"}))),(0,n.kt)("h2",{id:"design-requirements"},"Design Requirements"),(0,n.kt)("h2",{id:"architecture"},"Architecture"),(0,n.kt)("p",null,"ChronoLog is a new class of a distributed shared log store that will leverage physical time for achieving total ordering of log entries and\nwill utilize multiple storage tiers to distribute a log both horizontally and vertically (a model we call 3D data distribution)."),(0,n.kt)("h2",{id:"data-model--api"},"Data Model & API"),(0,n.kt)("h2",{id:"design-details"},"Design Details"),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Chronolog Design",src:a(4586).Z,width:"962",height:"680"})),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"The ChronoVisor"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Handles client connections"),(0,n.kt)("li",{parentName:"ul"},"Holds chronicle metadata information"),(0,n.kt)("li",{parentName:"ul"},"Acts as the global clock enforcing time synchronization between all server nodes"),(0,n.kt)("li",{parentName:"ul"},"Deployed on its own server node (usually a head node)"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"The ChronoKeeper"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Serves all tail operations such as record() (append) and playback() (tail-read)"),(0,n.kt)("li",{parentName:"ul"},"Stores incoming events in a distributed journal"),(0,n.kt)("li",{parentName:"ul"},"Deployed on all or a subset of compute nodes that are equipped with a fast flash storage"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"The ChronoStore"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Manages both intermediate storage resources (e.g., burst buffers or data staging resources) and the storage servers"),(0,n.kt)("li",{parentName:"ul"},"Has the ability to grow or shrink its resources offering an elastic solution that can react to the I/O traffic"),(0,n.kt)("li",{parentName:"ul"},"Organized into the ChronoGrapher and ChronoPlayer, which are responsible for writes and reads, respectively"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"The ChronoGrapher"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Continuously ingests events from the ChronoKeeper"),(0,n.kt)("li",{parentName:"ul"},"Uses a real-time data streaming approach to persist events to lower tiers of the hierarchy"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"The ChronoPlayer"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Serves historical reads in the form of replay() (catch-up read) calls")))),(0,n.kt)("h2",{id:"features--operations"},"Features & Operations"),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"ChronoKeeper",src:a(4998).Z,width:"901",height:"566"})),(0,n.kt)("h2",{id:"log-auto-tiering"},"Log Auto-Tiering"),(0,n.kt)("p",null,"To provide chronicle capacity scaling, ChronoLog moves data down to the next larger but slower tiers automatically. To achieve this,\nthe ChronoGrapher offers a very fast distributed data flushing solution, that can match the event production rate, by offering:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Real-time continuous data flushing"),(0,n.kt)("li",{parentName:"ul"},"Tunable parallelism via resource elasticity"),(0,n.kt)("li",{parentName:"ul"},"Storage device-aware random access"),(0,n.kt)("li",{parentName:"ul"},"A decoupled server-pull, instead of a client-push, eviction model")),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"ChronoGrapher",src:a(4339).Z,width:"768",height:"264"})),(0,n.kt)("p",null,"ChronoGrapher runs a data streaming job with three major steps represented as a DAG: event collection, story building, and story writing.\nEach node in the DAG is dynamic and elastic based on the incoming traffic estimated by the number of events and total size of data."),(0,n.kt)("h2",{id:"log-querying--range-retrieval"},"Log Querying & Range Retrieval"),(0,n.kt)("p",null,"The ChronoPlayer is responsible for executing historical read operations."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"ChronoPlayer",src:a(4789).Z,width:"768",height:"264"})),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Initialized by the ChronoVisor upon system initialization"),(0,n.kt)("li",{parentName:"ul"},"Accesses data from all available tiers"),(0,n.kt)("li",{parentName:"ul"},"Implemented by a data streaming approach"),(0,n.kt)("li",{parentName:"ul"},"Real-time, decoupled, and elastic architecture")),(0,n.kt)("h2",{id:"evaluation-results"},"Evaluation Results"),(0,n.kt)("h2",{id:"publications"},"Publications"),(0,n.kt)("h2",{id:"members"},"Members"),(0,n.kt)("h2",{id:"collaborators"},"Collaborators"),(0,n.kt)("h2",{id:"sponsor"},"Sponsor"),(0,n.kt)("p",null,"National Science Foundation (NSF CSSI-2104013)"),(0,n.kt)("p",null,(0,n.kt)("img",{src:a(1188).Z,width:"100"})))}u.isMDXComponent=!0},3161:(e,t,a)=>{a.d(t,{Z:()=>l});var r=a(7294),n=a(6010),i=a(866);function l(e){let{addMargin:t=!0,projectId:a}=e;const{isOpenSource:l=!1,isOurs:o=!1}=(0,i.R)(a);return l||o?r.createElement("div",{className:(0,n.Z)(t&&"margin-bottom--md"),style:{lineHeight:1}},o&&r.createElement("span",{className:"badge badge--primary margin-horiz--xs"},"GRC-LED"),l&&r.createElement("span",{className:"badge badge--secondary margin-horiz--xs"},"OPEN SOURCE")):null}},866:(e,t,a)=>{a.d(t,{R:()=>i,Z:()=>n});const r=[{id:"coeus",name:"Coeus",title:"Coeus: Accelerating Scientific Insights Using Enriched Metadata",shortDescription:"In collaboration with Sandia and Oak Ridge National Laboratories, coeus investigate the use of an active storage system to calculate derived quantities and support complex queries on scientific data (simulation and observational) as well as optimizing data placement across the storage hierarchy, with awareness of the resource limitations, to better support the scientific discovery process.",link:"/research/projects/coeus",isFeatured:!0,isOurs:!0,researchStatus:"r&d",status:"active",type:"funded"},{id:"chronolog",name:"ChronoLog",title:"ChronoLog: A High-Performance Storage Infrastructure for Activity and Log Workloads",shortDescription:"HPC applications generate more data than storage systems can handle, and it is becoming increasingly important to store activity (log) data generated by people and applications. ChronoLog is a hierarchical, distributed log store that leverages physical time to achieve log ordering and reduce contention while utilizing storage tiers to elastically scale the log capacity.",link:"/research/projects/chronolog",isFeatured:!0,isOpenSource:!0,isOurs:!0,researchStatus:"testing",status:"active",type:"funded"},{id:"iris",name:"IRIS",title:"IRIS: I/O Redirection Via Integrated Storage",shortDescription:"Various storage solutions exist and require specialized APIs and data models in order to use, which binds developers, applications, and entire computing facilities to using certain interfaces. Each storage system is designed and optimized for certain applications but does not perform well for others. IRIS is a unified storage access system that bridges the semantic gap between filesystems and object stores.",link:"/research/projects/iris",isFeatured:!1,isOpenSource:!0,isOurs:!0,researchStatus:"testing",status:"active",type:"funded"},{id:"hermes",name:"Hermes",title:"Hermes: Extending the HDF Library to Support Intelligent I/O Buffering for Deep Memory and Storage Hierarchy System",shortDescription:"To reduce the I/O bottleneck, complex storage hierarchies have been introduced. However, managing this complexity should not be left to application developers. Hermes is a middeware library that automatically manages buffering in heterogeneous storage environments.",link:"/research/projects/hermes",isFeatured:!0,isOpenSource:!0,isOurs:!0,researchStatus:"ready",status:"active",type:"funded"},{id:"dtio",name:"DTIO",title:"DTIO: A Data Task I/O Runtime",shortDescription:"In partnership with Argonne National Laboratory, DTIO investigates the use of a task framework for unifying complex I/O stacks and providing features such as resilience, fault-tolerance, and task replay.",link:"/research/projects/dtio",isFeatured:!0,isOurs:!0,researchStatus:"testing",status:"active",type:"funded"}],n=r;function i(e){return r.find((t=>t.id===e))}},1188:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/nsf-fb7efe9286a9b499c5907d82af3e70fd.png"},3933:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/logo-586977340bf4a28e2557b6e3fb3927a8.png"},4339:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/chronographer-e68152f8899959ad1c9696b01967dfbd.svg"},4998:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/chronokeeper-748b9121ea32d501e5134955b1a9acc4.svg"},4789:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/chronoplayer-0fb14b96bd4a6457f4405aa39316a5e2.svg"},4586:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/design-15413d3184fde0039e0937fe3ef53d07.svg"},2986:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/paradigm-1d265a5b3f99a9936fc4605049749e14.svg"},6754:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/software-453e49cd0d12ee1907c1fd4ea8e024b0.png"}}]);