"use strict";(self.webpackChunkgrc=self.webpackChunkgrc||[]).push([[88983],{28119:e=>{e.exports=JSON.parse('{"abstract":"GPUs are throughput-oriented processors that depend on mas-\\nsive multithreading to tolerate long latency memory accesses. The\\nlatest GPUs all are equipped with on-chip data caches to reduce\\nthe latency of memory accesses and save the bandwidth of NOC\\nand off-chip memory modules. But these tiny data caches are vul-\\nnerable to thrashing from massive multithreading, especially when\\ndivergent load instructions generate long bursts of cache accesses.\\nMeanwhile, the blocks of divergent loads exhibit high intra-warp\\nlocality and are expected to be atomically cached so that the issuing\\nwarp can fully hit in L1D in the next load issuance. However, GPU\\ncaches are not designed with enough awareness of either SIMD ex-\\necution model or memory divergence.\\nIn this work, we renovate the cache management policies to de-\\nsign a GPU-specific data cache, DaCache. This design starts with\\nthe observation that warp scheduling can essentially shape the lo-\\ncality pattern in cache access streams. Thus we incorporate the\\nwarp scheduling logic into insertion policy so that blocks are in-\\nserted into the LRU-chain according to their issuing warp\'s schedul-\\ning priority. Then we deliberately prioritize coherent loads over di-\\nvergent loads. In order to enable the thrashing resistance, the cache\\nways are partitioned by desired warp concurrency into two regions,\\nthe locality region and the thrashing region, so that replacement is\\nconstrained within the thrashing region. When no replacement can-\\ndidate is available in the thrashing region, incoming requests are\\nbypassed. We also implement a dynamic partition scheme based\\non the caching effectiveness that is sampled at runtime. Experi-\\nments show that DaCache achieves 40.4% performance improve-\\nment over the baseline GPU and outperform two state-of-the-art\\nthrashing resistant cache management techniques RRIP and DIP\\nby 40% and 24.9%, respectively.","authors":["B. Wang","W. Yu","X.-H. Sun","X. Wang"],"date":"June, 2015","links":{"bibtex":"http://cs.iit.edu/~scs/assets/files/wang2015dacache.bib","citation":"http://cs.iit.edu/~scs/assets/files/wang2015dacache.txt","pdf":"https://www.cs.fsu.edu/~yuw/pubs/2015-ICS-Yu.pdf"},"month":6,"slug":"wang-2015-dacache-057a","tags":[],"title":"DaCache: Memory Divergence-Aware GPU Cache Management","type":"Conference","venue":"29th International Conference on Supercomputing (ICS\'15), Newport Beach, CA. USA","year":2015}')}}]);