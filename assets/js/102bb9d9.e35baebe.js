"use strict";(self.webpackChunkgnosis=self.webpackChunkgnosis||[]).push([[9076],{3905:(e,n,t)=>{t.d(n,{Zo:()=>d,kt:()=>g});var a=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function l(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?l(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},l=Object.keys(e);for(a=0;a<l.length;a++)t=l[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)t=l[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var o=a.createContext({}),p=function(e){var n=a.useContext(o),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},d=function(e){var n=p(e.components);return a.createElement(o.Provider,{value:n},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},c=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,l=e.originalType,o=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),m=p(t),c=r,g=m["".concat(o,".").concat(c)]||m[c]||u[c]||l;return t?a.createElement(g,i(i({ref:n},d),{},{components:t})):a.createElement(g,i({ref:n},d))}));function g(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var l=t.length,i=new Array(l);i[0]=c;var s={};for(var o in n)hasOwnProperty.call(n,o)&&(s[o]=n[o]);s.originalType=e,s[m]="string"==typeof e?e:r,i[1]=s;for(var p=2;p<l;p++)i[p]=t[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}c.displayName="MDXCreateElement"},8735:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>i,default:()=>u,frontMatter:()=>l,metadata:()=>s,toc:()=>p});var a=t(7462),r=(t(7294),t(3905));const l={},i="DeepDriveMD",s={unversionedId:"jarvis/jarvis-cd/packages/deepdrivemd",id:"jarvis/jarvis-cd/packages/deepdrivemd",title:"DeepDriveMD",description:"Dependencies",source:"@site/docs/05-jarvis/02-jarvis-cd/08-packages/deepdrivemd.md",sourceDirName:"05-jarvis/02-jarvis-cd/08-packages",slug:"/jarvis/jarvis-cd/packages/deepdrivemd",permalink:"/docs/jarvis/jarvis-cd/packages/deepdrivemd",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"CM1",permalink:"/docs/jarvis/jarvis-cd/packages/cm1"},next:{title:"Nyx",permalink:"/docs/jarvis/jarvis-cd/packages/nyx"}},o={},p=[{value:"Dependencies",id:"dependencies",level:2},{value:"Prepare Conda Environment from Config Files",id:"prepare-conda-environment-from-config-files",level:3},{value:"Prepare Conda",id:"prepare-conda",level:4},{value:"First git clone this repo and save it to <code>$DDMD_PATH</code>",id:"first-git-clone-this-repo-and-save-it-to-ddmd_path",level:4},{value:"Create the two conda environments",id:"create-the-two-conda-environments",level:4},{value:"Update python packages in both conda environments",id:"update-python-packages-in-both-conda-environments",level:4},{value:"Hermes Dependencies",id:"hermes-dependencies",level:2},{value:"In Ares",id:"in-ares",level:3},{value:"Personal Machine",id:"personal-machine",level:3},{value:"Installation",id:"installation",level:2},{value:"Usage",id:"usage",level:2},{value:"Stage 1 : OPENMM",id:"stage-1--openmm",level:3},{value:"Environment variables note",id:"environment-variables-note",level:4},{value:"Stage 2 : AGGREGATE",id:"stage-2--aggregate",level:3},{value:"Stage 3 : TRAINING",id:"stage-3--training",level:3},{value:"Stage 4 : INFERENCE",id:"stage-4--inference",level:3}],d={toc:p},m="wrapper";function u(e){let{components:n,...t}=e;return(0,r.kt)(m,(0,a.Z)({},d,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"deepdrivemd"},"DeepDriveMD"),(0,r.kt)("h2",{id:"dependencies"},"Dependencies"),(0,r.kt)("p",null,"You can setup environments two ways"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#ddmd-conda-environment-from-config-files"},"create environment from config files")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/candiceT233/deepdrivemd_pnnl/blob/main/docs/conda_env/README.md"},"buid the conda environment from scratch"))),(0,r.kt)("h3",{id:"prepare-conda-environment-from-config-files"},"Prepare Conda Environment from Config Files"),(0,r.kt)("h4",{id:"prepare-conda"},"Prepare Conda"),(0,r.kt)("p",null,"Get the ",(0,r.kt)("inlineCode",{parentName:"p"},"miniconda3")," installation script and run it"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nbash Miniconda3-latest-Linux-x86_64.sh.sh\n")),(0,r.kt)("p",null,"The current conda version tested work that works ",(0,r.kt)("inlineCode",{parentName:"p"},"conda 23.3.1"),"."),(0,r.kt)("h4",{id:"first-git-clone-this-repo-and-save-it-to-ddmd_path"},"First git clone this repo and save it to ",(0,r.kt)("inlineCode",{parentName:"h4"},"$DDMD_PATH")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"export CONDA_OPENMM=openmm7_ddmd\nexport CONDA_PYTORCH=ddmd_pytorch\nexport DDMD_PATH=${PWD}/deepdrivemd\nexport MOLECULES_PATH=$DDMD_PATH/submodules/molecules\ngit clone --recursive https://github.com/candiceT233/deepdrivemd_pnnl.git $DDMD_PATH\ncd $DDMD_PATH\n")),(0,r.kt)("h4",{id:"create-the-two-conda-environments"},"Create the two conda environments"),(0,r.kt)("p",null,"Name your two environment names ",(0,r.kt)("inlineCode",{parentName:"p"},"$CONDA_OPENMM")," ",(0,r.kt)("inlineCode",{parentName:"p"},"$CONDA_PYTORCH"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"cd $DDMD_PATH\nconda env create -f ${DDMD_PATH}/docs/conda_env/ddmd_openmm7.yaml --name=${CONDA_OPENMM}\nconda env create -f ${DDMD_PATH}/docs/conda_env/ddmd_pytorch.yaml --name=${CONDA_PYTORCH}\n")),(0,r.kt)("p",null,"If mdtools fails to install, that's ok. It will be handled in step 4."),(0,r.kt)("h4",{id:"update-python-packages-in-both-conda-environments"},"Update python packages in both conda environments"),(0,r.kt)("p",null,"Update CONDA_OPENMM"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"source activate $CONDA_OPENMM\ncd $DDMD_PATH/submodules/MD-tools\npip install .\ncd $DDMD_PATH/submodules/molecules\npip install .\nconda deactivate\n")),(0,r.kt)("p",null,"Update CONDA_PYTORCH"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"source activate $CONDA_PYTORCH\ncd $DDMD_PATH/submodules/MD-tools\npip install .\ncd $DDMD_PATH/submodules/molecules\npip install .\nconda deactivate\n")),(0,r.kt)("h2",{id:"hermes-dependencies"},"Hermes Dependencies"),(0,r.kt)("h3",{id:"in-ares"},"In Ares"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"module load hermes/pnnl-tz3s7yx\n")),(0,r.kt)("p",null,"this automatically loads the Hermes build with VFD, and it's HDF5 dependency."),(0,r.kt)("h3",{id:"personal-machine"},"Personal Machine"),(0,r.kt)("p",null,"If building Hermes yourself:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Sequential HDF5 >= 1.14.0"),(0,r.kt)("li",{parentName:"ul"},"Hermes>=1.0 with VFD and POSIX Adaptor support")),(0,r.kt)("p",null,"Build HDF5"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"scspkg create hdf5\ncd `scspkg pkg src hdf5`\ngit clone https://github.com/HDFGroup/hdf5.git -b hdf5_1_14_0\ncd hdf5\nmkdir build\ncd build\ncmake ../ -DHDF5_BUILD_HL_LIB=ON -DCMAKE_INSTALL_PREFIX=`scspkg pkg root hdf5`\nmake -j8\nmake install\n")),(0,r.kt)("p",null,"Install Hermes with Custom HDF5"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"spack install mochi-thallium~cereal@0.10.1 cereal catch2@3.0.1 mpich@3.3.2 yaml-cpp boost@1.7\nspack load mochi-thallium~cereal@0.10.1 cereal catch2@3.0.1 mpich@3.3.2 yaml-cpp boost@1.7\nmodule load hdf5\n")),(0,r.kt)("p",null,"NOTE: this only needs to be done for the CONDA_OPENMM environment, since both environment use the same exact python version. HDF5 will be compiled the same. However, these commands must be executed before source active $CONDA_PYTORCH to avoid overriding the python version."),(0,r.kt)("h2",{id:"installation"},"Installation"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"h5py==3.8.0")," is required for ",(0,r.kt)("inlineCode",{parentName:"li"},"hdf5-1.14.0")," and ",(0,r.kt)("inlineCode",{parentName:"li"},"Hermes>=1.0")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"pip install h5py==3.8.0")," should be run after deepdrivemd installation due to version restriction with pip"),(0,r.kt)("li",{parentName:"ul"},"makesure you have ",(0,r.kt)("inlineCode",{parentName:"li"},"hdf5-1.14.0")," installed and added to $PATH before installing h5py (otherwise it will download hdf5-1.12.0 by default)")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"module load hdf5\n\ncd $DDMD_PATH\nsource activate $CONDA_OPENMM\npip install -e .\npip uninstall h5py; pip install h5py==3.8.0\nconda deactivate\n\nsource activate $CONDA_PYTORCH\npip install -e .\npip uninstall h5py; pip install h5py==3.8.0\nconda deactivate\n")),(0,r.kt)("h2",{id:"usage"},"Usage"),(0,r.kt)("p",null,"Below describes running one iteration of the 4-stages pipeline. \\\nSet up experiment path in ",(0,r.kt)("inlineCode",{parentName:"p"},"$EXPERIMENT_PATH"),", this will store all output files and log files from all stages."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"EXPERIMENT_PATH=~/ddmd_runs\nmkdir -p $EXPERIMENT_PATH\n")),(0,r.kt)("hr",null),(0,r.kt)("h3",{id:"stage-1--openmm"},"Stage 1 : OPENMM"),(0,r.kt)("p",null,"Run code:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"source activate $CONDA_OPENMM\n\nPYTHONPATH=$DDMD_PATH:$MOLECULES_PATH python $DDMD_PATH/deepdrivemd/sim/openmm/run_openmm.py -c $YAML_PATH/molecular_dynamics_stage_test.yaml\n")),(0,r.kt)("p",null,"This stage runs simulation, minimally you have to run 12 simulation tasks for stage 3 & 4 to work. So you must run the above command at least 12 times and each time with a different ",(0,r.kt)("inlineCode",{parentName:"p"},"TASK_IDX_FORMAT"),"."),(0,r.kt)("h4",{id:"environment-variables-note"},"Environment variables note"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"TASK_IDX_FORMAT")," : give a different task ID format for each openmm task, starts with ",(0,r.kt)("inlineCode",{parentName:"li"},"task0000")," up to ",(0,r.kt)("inlineCode",{parentName:"li"},"task0011")," for 12 tasks."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"SIM_LENGTH")," : The simulation size, must be at least ",(0,r.kt)("inlineCode",{parentName:"li"},"0.1")," for stage 3 & 4 to work."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"GPU_IDX")," : set it to 0 since GPU is not used"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"YAML_PATH")," : The yaml file that contains the test configuration for the first stage")),(0,r.kt)("p",null,"Setup environment variables and paths"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'SIM_LENGTH=0.1\nGPU_IDX=0\nTASK_IDX_FORMAT="task0000"\nSTAGE_IDX=0\nOUTPUT_PATH=$EXPERIMENT_PATH/molecular_dynamics_runs/stage0000/$TASK_IDX_FORMAT\nYAML_PATH=$DDMD_PATH/test/bba\nmkdir -p $OUTPUT_PATH\n')),(0,r.kt)("p",null,"In the yaml file ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/candiceT233/deepdrivemd_pnnl/blob/main/test/bba/molecular_dynamics_stage_test.yaml"},(0,r.kt)("inlineCode",{parentName:"a"},"molecular_dynamics_stage_test.yaml")),", makesure to modify the following fields accordingly:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"nano ${DDMD_PATH}/test/bba/molecular_dynamics_stage_test.yaml\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"experiment_directory: $EXPERIMENT_PATH\nstage_idx: $STAGE_IDX\noutput_path: $OUTPUT_PATH\npdb_file: $DDMD_PATH/data/bba/system/1FME-unfolded.pdb\ninitial_pdb_dir: $DDMD_PATH/data/bba\nsimulation_length_ns: $SIM_LENGTH\nreference_pdb_file: $DDMD_PATH/data/bba/1FME-folded.pdb\ngpu_idx: $GPU_IDX\n")),(0,r.kt)("p",null,"Sample output under one task folder (total 12 tasks folders):"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-log"},"ls -l $OUTPUT_PATH\n-rw-rw-r-- 1 username username  722 Aug 11 01:08 aggregate_stage_test.yaml\n-rw-rw-r-- 1 username username  786 Aug 10 21:50 molecular_dynamics_stage_test.yaml\n-rw-rw-r-- 1 username username 599K Aug 10 21:56 stage0000_task0000.dcd\n-rw-rw-r-- 1 username username 164K Aug 10 21:56 stage0000_task0000.h5\n-rw-rw-r-- 1 username username  39K Aug 10 21:50 system__1FME-unfolded.pdb\n")),(0,r.kt)("hr",null),(0,r.kt)("h3",{id:"stage-2--aggregate"},"Stage 2 : AGGREGATE"),(0,r.kt)("p",null,"Run code:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"source activate $CONDA_OPENMM\n\nPYTHONPATH=$DDMD_PATH/ python $DDMD_PATH/deepdrivemd/aggregation/basic/aggregate.py -c $YAML_PATH/aggregate_stage_test.yaml\n")),(0,r.kt)("p",null,"This stage only need to be run one time, it aggregates all the ",(0,r.kt)("inlineCode",{parentName:"p"},"stage0000_task0000.h5")," files from simulation into a single ",(0,r.kt)("inlineCode",{parentName:"p"},"aggregated.h5")," file."),(0,r.kt)("p",null,"Setup a different output path to the first openmm task folder:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"OUTPUT_PATH=$EXPERIMENT_PATH/machine_learning_runs/stage0000/task0000\n\nmkdir -p $OUTPUT_PATH\n")),(0,r.kt)("p",null,"In the yaml file ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/candiceT233/deepdrivemd_pnnl/blob/main/test/bba/aggregate_stage_test.yaml"},(0,r.kt)("inlineCode",{parentName:"a"},"aggregate_stage_test.yaml")),", makesure to modify the following fields accordingly:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"experiment_directory: $EXPERIMENT_PATH\nstage_idx: $STAGE_IDX\npdb_file: $DDMD_PATH/data/bba/system/1FME-unfolded.pdb\nreference_pdb_file: $DDMD_PATH/data/bba/1FME-folded.pdb\n")),(0,r.kt)("p",null,"Expected output:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-log"},"ls -l $OUTPUT_PATH | grep aggregated\n-rw-rw-r-- 1 username username 1.6M Aug 11 01:08 aggregated.h5\n")),(0,r.kt)("hr",null),(0,r.kt)("h3",{id:"stage-3--training"},"Stage 3 : TRAINING"),(0,r.kt)("p",null,"Run code:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"source activate $CONDA_PYTORCH\n\nPYTHONPATH=$DDMD_PATH/:$MOLECULES_PATH python $DDMD_PATH/deepdrivemd/models/aae/train.py -c $YAML_PATH/training_stage_test.yaml\n")),(0,r.kt)("p",null,"When the code run, python might show warning messages that can be ignored."),(0,r.kt)("p",null,"Setup a different output path:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"OUTPUT_PATH=$EXPERIMENT_PATH/machine_learning_runs/stage000$STAGE_IDX/$TASK_IDX_FORMAT\n\nmkdir -p $OUTPUT_PATH\n")),(0,r.kt)("p",null,"In the yaml file ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/candiceT233/deepdrivemd_pnnl/blob/main/test/bba/training_stage_test.yaml"},(0,r.kt)("inlineCode",{parentName:"a"},"training_stage_test.yaml")),", makesure to modify the following fields accordingly:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"experiment_directory: $EXPERIMENT_PATH\noutput_path: $OUTPUT_PATH\n")),(0,r.kt)("p",null,"Expected output:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-log"},"ls -l $OUTPUT_PATH\ndrwxrwxr-x 2 username username 4.0K Aug 11 01:09 checkpoint\n-rw-rw-r-- 1 username username 1.5M Aug 11 01:10 discriminator-weights.pt\ndrwxrwxr-x 2 username username 4.0K Aug 11 01:10 embeddings\n-rw-rw-r-- 1 username username 2.0M Aug 11 01:10 encoder-weights.pt\n-rw-rw-r-- 1 username username 2.7M Aug 11 01:10 generator-weights.pt\n-rw-rw-r-- 1 username username 1.2K Aug 11 01:10 loss.json\n-rw-rw-r-- 1 username username  495 Aug 11 01:08 model-hparams.json\n-rw-rw-r-- 1 username username   82 Aug 11 01:08 optimizer-hparams.json\n-rw-rw-r-- 1 username username  884 Aug 11 01:08 training_stage_test.yaml\n-rw-rw-r-- 1 username username 1.3K Aug 11 01:08 virtual-h5-metadata.json\n-rw-rw-r-- 1 username username  10K Aug 11 01:08 virtual_stage0000_task0000.h5\n")),(0,r.kt)("hr",null),(0,r.kt)("h3",{id:"stage-4--inference"},"Stage 4 : INFERENCE"),(0,r.kt)("p",null,"Run code:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"source activate $CONDA_PYTORCH\n\nOMP_NUM_THREADS=4 PYTHONPATH=$DDMD_PATH/:$MOLECULES_PATH python $DDMD_PATH/deepdrivemd/agents/lof/lof.py -c $YAML_PATH/inference_stage_test.yaml\n")),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"OMP_NUM_THREADS")," can be changed."),(0,r.kt)("p",null,"Update environment variables:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"STAGE_IDX=3\n\nOUTPUT_PATH=$EXPERIMENT_PATH/inference_runs/stage0000/$TASK_IDX_FORMAT\n\nmkdir -p $OUTPUT_PATH\n")),(0,r.kt)("p",null,"In the yaml file ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/candiceT233/deepdrivemd_pnnl/blob/main/test/bba/inference_stage_test.yaml"},(0,r.kt)("inlineCode",{parentName:"a"},"inference_stage_test.yaml")),", makesure to modify the following fields accordingly:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"experiment_directory: $EXPERIMENT_PATH\nstage_idx: $STAGE_IDX\noutput_path: $OUTPUT_PATH\n")),(0,r.kt)("p",null,"Expected output files:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-log"},"ls -l $OUTPUT_PATH\n-rw-rw-r-- 1 username username  479 Aug 11 01:10 inference_stage_test.yaml\n-rw-rw-r-- 1 username username 1.5K Aug 11 01:10 virtual-h5-metadata.json\n-rw-rw-r-- 1 username username  18K Aug 11 01:10 virtual_stage0003_task0000.h5\n")))}u.isMDXComponent=!0}}]);