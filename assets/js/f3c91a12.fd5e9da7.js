"use strict";(self.webpackChunkgrc=self.webpackChunkgrc||[]).push([[23993],{51811:e=>{e.exports=JSON.parse('{"abstract":"Data volume grows dramatically in the era of big\\ndata. To save capital cost on storage hardware, datacenters\\ncurrently prefer using erasure coding rather than simply\\nreplication to resist data loss. Erasure coding can provide\\nequivalent three-way fault tolerance to HDFS\'s default three\\nreplication mechanism but degrades data availability for task\\nscheduling. In an erasure-coded system, data reconstruction\\ntime will be paid while tasks access the missing blocks during\\nMapReduce job processing. Tasks\' accessing corrupt data\\nintroduces task stragglers and degrades resource utilization.\\nTo overcome these challenges, we propose a novel mechanism,\\nDominoes, that coordinates lightweight data states checking\\nand job scheduling to hide such recovery penalty during job\\nprocessing and enhances job throughputs. The experimental\\nresults confirm Dominoes\' effectiveness and efficiency that\\nimproves job throughput by 9% to 9.7% under failure at an\\noverhead of 2.6% for failure-free jobs.","authors":["X. Yang","C. Feng","Z. Xu","X.-H. Sun"],"date":"December, 2015","links":{"bibtex":"http://cs.iit.edu/~scs/assets/files/yang2015dominoes.bib","citation":"http://cs.iit.edu/~scs/assets/files/yang2015dominoes.txt","pdf":"http://cs.iit.edu/~scs/assets/files/dominoes.pdf"},"month":12,"slug":"yang-2015-dominoes-de0a","tags":[],"title":"Dominoes: Speculative Repair in Erasure Coded Hadoop System","type":"Conference","venue":"22nd annual IEEE International Conference on High Performance Computing (HiPC 2015), Bengaluru, India","year":2015}')}}]);