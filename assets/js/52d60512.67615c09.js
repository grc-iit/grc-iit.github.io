"use strict";(self.webpackChunkgrc=self.webpackChunkgrc||[]).push([[11064],{78687:e=>{e.exports=JSON.parse('{"abstract":"The scale of scientific data generated by experi-\\nmental facilities and simulations on high-performance computing\\nfacilities has been growing rapidly. In many cases, this data\\nneeds to be transferred rapidly and reliably to remote facilities\\nfor storage, analysis, sharing etc. At the same time, users want\\nto verify the integrity of the data by doing a checksum after\\nthe data has been written to disk at the destination, to ensure\\nthe file has not been corrupted, for example due to network or\\nstorage data corruption, software bugs or human error. This end-\\nto-end integrity verification creates additional overhead (extra\\ndisk I/O and more computation) and increases the overall data\\ntransfer time. In this paper, we evaluate strategies to maximize\\nthe overlap between data transfer and checksum computation.\\nMore specifically, we evaluate file-level and block-level (with\\nvarious block sizes) pipelining to overlap data transfer and\\nchecksum computation. We evaluate these pipelining approaches\\nin the context of GridFTP, a widely used protocol for science\\ndata transfers. We conducted both theoretical analysis and real\\nexperiments to evaluate our methods. The results show that\\nblock-level pipelining is an effective method in maximizing the\\noverlap between data transfer and checksum computation and\\ncan improve the overall data transfer time with end-to-end\\nintegrity verification by up to 70% compared to the sequential\\nexecution of transfer and checksum, and by up to 60% compared\\nto file-level pipelining.","authors":["S. Liu","E.-S. Jun","R. Kettimuthu","X.-H. Sun","M. Papka"],"date":"December, 2016","doi":"10.1109/bigdata.2016.7840953","links":{"bibtex":"http://cs.iit.edu/~scs/assets/files/liu2016towards.bib","citation":"http://cs.iit.edu/~scs/assets/files/liu2016towards.txt","pdf":"https://www.mcs.anl.gov/~kettimut/publications/BigData16.pdf"},"month":12,"slug":"liu-2016-towards-optimizing-8e1c","tags":[],"title":"Towards Optimizing Large-Scale Data Transfers with End-to-End Integrity Verification","type":"Workshop","venue":"4th International Workshop on Distributed Storage Systems and Coding for Big Data, in conjunction with IEEE BigData 2016. Washington, D.C., USA","year":2016}')}}]);