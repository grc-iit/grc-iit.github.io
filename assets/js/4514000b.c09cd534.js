"use strict";(self.webpackChunkgnosis=self.webpackChunkgnosis||[]).push([[9306],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>c});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},m=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},d="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),d=p(n),u=r,c=d["".concat(s,".").concat(u)]||d[u]||h[u]||i;return n?a.createElement(c,o(o({ref:t},m),{},{components:n})):a.createElement(c,o({ref:t},m))}));function c(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[d]="string"==typeof e?e:r,o[1]=l;for(var p=2;p<i;p++)o[p]=n[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},9329:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>l,toc:()=>p});var a=n(7462),r=(n(7294),n(3905));const i={},o="Building Hermes",l={unversionedId:"hermes/getting-started",id:"hermes/getting-started",title:"Building Hermes",description:"There are several ways to obtain a working Hermes installation. Information on",source:"@site/docs/03-hermes/02-getting-started.md",sourceDirName:"03-hermes",slug:"/hermes/getting-started",permalink:"/docs/hermes/getting-started",draft:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Main Scenario",permalink:"/docs/hermes/index"},next:{title:"Configuration",permalink:"/docs/hermes/configuration"}},s={},p=[{value:"Deploying Resources",id:"deploying-resources",level:2},{value:"Adapters",id:"adapters",level:2},{value:"A note about Address Sanitization (libasan)",id:"a-note-about-address-sanitization-libasan",level:3},{value:"Deploying an Application with Hermes",id:"deploying-an-application-with-hermes",level:3},{value:"Workload",id:"workload",level:2},{value:"Target system",id:"target-system",level:2},{value:"Clients",id:"clients",level:3},{value:"Storage Tiers",id:"storage-tiers",level:3},{value:"Hermes configuration",id:"hermes-configuration",level:2},{value:"Daemon (server) configuration",id:"daemon-server-configuration",level:3},{value:"Defining the buffering locations",id:"defining-the-buffering-locations",level:4},{value:"Running",id:"running",level:2},{value:"IOR Baseline",id:"ior-baseline",level:3},{value:"IOR with Hermes",id:"ior-with-hermes",level:3}],m={toc:p},d="wrapper";function h(e){let{components:t,...i}=e;return(0,r.kt)(d,(0,a.Z)({},m,i,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"building-hermes"},"Building Hermes"),(0,r.kt)("p",null,"There are several ways to obtain a working Hermes installation. Information on\ndependencies can be found in the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/HDFGroup/hermes/blob/master/README.md"},"README"),"."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://hub.docker.com/r/hdfgroup/hermes"},"Docker Image"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"We also maintain Dockerfiles for ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/HDFGroup/hermesblob/master/dev.Dockerfile"},"Hermes\ndevelopment")," and ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/HDFGroup/hermesblob/master/deps.Dockerfile"},"Hermes\ndependencies")))),(0,r.kt)("li",{parentName:"ul"},"CMake",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Instructions can be found in the ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/HDFGroup/hermes/blob/master/README.md"},"README")))),(0,r.kt)("li",{parentName:"ul"},"Spack",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Instructions can be found in the ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/HDFGroup/hermes/blob/master/README.md"},"README"))))),(0,r.kt)("p",null,"If you get stuck, the root of the repository contains a ",(0,r.kt)("inlineCode",{parentName:"p"},"ci")," folder where we\nkeep the scripts we use to build and test Hermes in a Github Actions workflow.\nThe workflow file itself is ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/HDFGroup/hermes/blob/master/.github/workflows/main.yml"},"here"),"."),(0,r.kt)("h2",{id:"deploying-resources"},"Deploying Resources"),(0,r.kt)("p",null,"Hermes is an ",(0,r.kt)("em",{parentName:"p"},"application extension"),". Storage resources are deployed under\nHermes control by"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/docs/hermes/configuration"},"Configuring Hermes")," for your system ",(0,r.kt)("em",{parentName:"li"},"and")," application"),(0,r.kt)("li",{parentName:"ol"},'Making your application "Hermes-aware"')),(0,r.kt)("p",null,"An application can be made aware of Hermes in at least three different ways:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Through ",(0,r.kt)("a",{parentName:"li",href:"/docs/hermes/adapters"},"Hermes Adapters"),", ",(0,r.kt)("inlineCode",{parentName:"li"},"LD_PRELOAD"),"-able shared libraries\nwhich intercept common I/O middleware calls such as UNIX STDIO, POSIX, and\nMPI-IO (NOTE: when Hermes is compiled with DHERMES_USE_ADDRESS_SANITIZER=ON,\nwhich is ON by default, you must also ensure that libasan is preloaded first,\nbefore anything else)")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"By directly targeting the Hermes native API")),(0,r.kt)("p",null,"These options represent different use cases and trade-offs, for example, with\nrespect to expected performance gains and required code change."),(0,r.kt)("h2",{id:"adapters"},"Adapters"),(0,r.kt)("p",null,"When using the ",(0,r.kt)("inlineCode",{parentName:"p"},"STDIO")," adapter (intercepting ",(0,r.kt)("inlineCode",{parentName:"p"},"fopen"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"fwrite"),", etc.) and the\n",(0,r.kt)("inlineCode",{parentName:"p"},"POSIX")," adapter (intercepting ",(0,r.kt)("inlineCode",{parentName:"p"},"open"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"write"),", etc.), there are multiple ways to\ndeploy Hermes with an existing application."),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},(0,r.kt)("strong",{parentName:"p"},"NOTE:")," The ",(0,r.kt)("inlineCode",{parentName:"p"},"MPI-IO")," adapter is still experimental, and only supports MPICH\nat this time.")),(0,r.kt)("h3",{id:"a-note-about-address-sanitization-libasan"},"A note about Address Sanitization (libasan)"),(0,r.kt)("p",null,"If you compile hermes with DHERMES_USE_ADDRESS_SANITIZER=ON,\nyou must LD_PRELOAD the libasan\nused to build Hermes, in addition to the interceptor. To locate libasan,\nrun the following command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"gcc -print-file-name=libasan.so\n")),(0,r.kt)("p",null,"Note that libasan will detect memory leaks and errors in the program\nlinking to hermes as well. To avoid detecting memory leaks in the\nclient program, do the following:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"# Create or modify a file for storing libasan exclusions:\nnano ${HERMES_ROOT}/test/data/asan.supp\n\n# Set the libasan environment variable to point to the file\nLSAN_OPTIONS=suppressions=${HERMES_ROOT}/test/data/asan.supp\n")),(0,r.kt)("p",null,"Check the example in the section below (Hermes services running in same process\nas the application) to see how to use hermes + asan together."),(0,r.kt)("h3",{id:"deploying-an-application-with-hermes"},"Deploying an Application with Hermes"),(0,r.kt)("p",null,"The Hermes daemon is responsible for tracking various metadata, and it is\nrequired to be launched before your application. There should only be\none Hermes daemon per node. This can be accomplished using SSH or MPI.\nThe following example uses MPICH to deploy hermes on a cluster of two nodes.\nWe then use MPICH to finalize the daemon and flush all remaining content\nback to the PFS."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"# We must start one and only one Hermes daemon on each node.\n# This job is started in the background so the terminal doesn't block forever\n# HERMES_CONF is the configuration of the server.\nmpirun -n 2 -ppn 1 \\\n  -genv PATH=${PATH} \\\n  -genv LD_LIBRARY_PATH=${LD_LIBRARY_PATH} \\\n  -genv HERMES_CONF=/path/to/hermes.yaml \\\n  ${HERMES_INSTALL_DIR}/bin/hermes_daemon &\n\n# Now we can start our application\n# HERMES_CONF is the same as the one when spawning the daemon\n# HERMES_CLIENT_CONF contains any parameters relevant to the specific program\nmpirun -n 4 -ppn 2 \\\n  -genv PATH=${PATH} \\\n  -genv LD_LIBRARY_PATH=${LD_LIBRARY_PATH} \\\n  -genv LD_PRELOAD=${HERMES_INSTALL_DIR}/lib/libhermes_posix.so \\\n  -genv HERMES_CLIENT_CONF=/path/to/hermes_client.yaml \\\n  -genv HERMES_CONF=/path/to/hermes_server.yaml \\\n  ./my_app\n\n# Now we can finalize\n# This will automatically flush all dirty data remaining back to the PFS\nHERMES_CONF=/path/to/hermes.yaml \\\n${HERMES_INSTALL_DIR}/bin/finalize_hermes\n")),(0,r.kt)("h1",{id:"hermes-tutorial"},"Hermes Tutorial"),(0,r.kt)("p",null,"Here we will walk through an entire example of using Hermes with\n",(0,r.kt)("a",{parentName:"p",href:"https://github.com/hpc/ior"},"IOR"),". IOR supports several I/O APIs (",(0,r.kt)("inlineCode",{parentName:"p"},"-a")," option),\nincluding POSIX, MPI-IO, and HDF5. Hermes has adapters for POSIX, MPI-IO, and HDF5.\nFor serial (single process) HDF5, the Hermes VFD can be enabled via environment variable\nas described ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/HDFGroup/hermes/tree/master/adapter/vfd#method-3-dynamically-loaded-by-environment-variable"},"here"),". Parallel HDF5 can use the MPI-IO adapter.\nFor this tutorial, we'll focus on POSIX. We assume you already have working\nHermes and IOR installations. See the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/HDFGroup/hermes/blob/master/README.md"},"README")," for\nHermes installation details."),(0,r.kt)("h2",{id:"workload"},"Workload"),(0,r.kt)("p",null,"We will simulate a checkpoint/restart workload in which a group of processes\neach write a checkpoint file, and then another group of processes on different\nnodes reads the checkpoint files. In the default case, the checkpoint files will\nbe written to and then read from the parallel file system. When running with\nHermes, the data will be buffered in fast, local media resulting in a nice\nspeedup with no code changes required."),(0,r.kt)("h2",{id:"target-system"},"Target system"),(0,r.kt)("h3",{id:"clients"},"Clients"),(0,r.kt)("p",null,"I'm running on a cluster with 8 client nodes, each with the following\ncharacteristics:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz\n40 cores (Hyperthreading enabled)\n46 GiB DRAM\n40 Gbps ethernet with RoCE capability\n")),(0,r.kt)("h3",{id:"storage-tiers"},"Storage Tiers"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Name"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"),(0,r.kt)("th",{parentName:"tr",align:null},"Measured Write Bandwidth"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"PFS"),(0,r.kt)("td",{parentName:"tr",align:null},"OrangeFS running on 8 server nodes, backed by HDDs"),(0,r.kt)("td",{parentName:"tr",align:null},"536 MiB/s")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"NVMe"),(0,r.kt)("td",{parentName:"tr",align:null},"Node-local NVMe attached SSDs."),(0,r.kt)("td",{parentName:"tr",align:null},"1918 MiB/s")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"RAM"),(0,r.kt)("td",{parentName:"tr",align:null},"Node-local DRAM."),(0,r.kt)("td",{parentName:"tr",align:null},"79,061 MiB/s")))),(0,r.kt)("h2",{id:"hermes-configuration"},"Hermes configuration"),(0,r.kt)("p",null,"Here we describe the Hermes configuration format. Hermes has two configurations:\none for the daemon and one for the client program. We will briefly discuss\neach here.\nSee ",(0,r.kt)("a",{parentName:"p",href:"/docs/hermes/configuration"},"Configuration")," for more details."),(0,r.kt)("h3",{id:"daemon-server-configuration"},"Daemon (server) configuration"),(0,r.kt)("p",null,"For a documented example of how to create a Hermes configuration, please\ncheck the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/HDFGroup/hermes/blob/master/config/hermes_server_default.yaml"},"default configuration"),".\nNote, the default config is designed for single-node cases. We use YAML to\ndefine the Hermes configuration format."),(0,r.kt)("h4",{id:"defining-the-buffering-locations"},"Defining the buffering locations"),(0,r.kt)("p",null,"First, we should define the kind of storage devices that are targeted for\nintermediate buffering."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'devices:\n  ram:\n    mount_point: ""\n    capacity: 50MB\n    block_size: 4KB\n    slab_sizes: [4KB, 16KB, 64KB, 1MB]\n    bandwidth: 6000MBps\n    latency: 15us\n    is_shared_device: false\n    borg_capacity_thresh: [0.0, 1.0]\n  nvme:\n    mount_point: "/mnt/nvme/hermes_nvme"\n    capacity: 100MB\n    block_size: 4KB\n    slab_sizes: [4KB, 16KB, 64KB, 1MB]\n    bandwidth: 1GBps\n    latency: 600us\n    is_shared_device: false\n    borg_capacity_thresh: [0.0, 1.0]\n  pfs:\n    mount_point: "${HOME}/hermes_pfs"\n    capacity: 100MB\n    block_size: 64KB # The stripe size of PFS\n    slab_sizes: [4KB, 16KB, 64KB, 1MB]\n    bandwidth: 100MBps # Per-device bandwidth\n    latency: 200ms\n    is_shared_device: true\n    borg_capacity_thresh: [0.0, 1.0]\n')),(0,r.kt)("p",null,"Here we have a YAML dictionary called devices. A semantic name is then provided\nfor each device targeted for buffering. To tell Hermes a device is considered\nRAM, we use mount_point being the empty string. For other devices, this is\ncan be a path to a directory located on a filesystem."),(0,r.kt)("h4",{id:""}),(0,r.kt)("h2",{id:"running"},"Running"),(0,r.kt)("h3",{id:"ior-baseline"},"IOR Baseline"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"mpirun -n 48 -ppn 12 \\\n  ior -w -r -o /PFS/USER/ior.out -t 1m -b 128m -F -e -Y -C -O summaryFormat=CSV\n")),(0,r.kt)("p",null,"Here we launch 48 IOR processes across 4 nodes. The IOR options are explained in\nthe following table."),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Flag"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-w"),(0,r.kt)("td",{parentName:"tr",align:null},"Perform write")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-r"),(0,r.kt)("td",{parentName:"tr",align:null},"Perform read")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-o"),(0,r.kt)("td",{parentName:"tr",align:null},"Output/Input file")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-t"),(0,r.kt)("td",{parentName:"tr",align:null},"Size per write")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-b"),(0,r.kt)("td",{parentName:"tr",align:null},"Total I/O size per rank")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-F"),(0,r.kt)("td",{parentName:"tr",align:null},"Create one file for each process")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-e"),(0,r.kt)("td",{parentName:"tr",align:null},"Call ",(0,r.kt)("inlineCode",{parentName:"td"},"fsync")," on file close.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-Y"),(0,r.kt)("td",{parentName:"tr",align:null},"Call ",(0,r.kt)("inlineCode",{parentName:"td"},"fsync")," after each write.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-C"),(0,r.kt)("td",{parentName:"tr",align:null},"Shuffle ranks so that they read from different nodes than they wrote to")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-O summaryFormat"),(0,r.kt)("td",{parentName:"tr",align:null},"Show the output in a compact, CSV format")))),(0,r.kt)("p",null,"Some of these options require justification."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"-Y"),": We do direct (non-buffered) I/O in order to simulate a situation with\nhigh RAM pressure. If the application is using most of the RAM, then the OS\npage cache will have less RAM available for buffering."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"-C"),": This option simulates a situation where different nodes read the\ncheckpoint than the ones that wrote it, resulting in a situation where the\ncheckpoint cannot be read from the page cache, and forcing the app to go to\nthe PFS.")),(0,r.kt)("p",null,"Here are the results:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"access,bw(MiB/s),IOPS,Latency,block(KiB),xfer(KiB),open(s),wr/rd(s),close(s),total(s),numTasks,iter\nwrite,30.3120,30.3795,1.5543,131072.0000,1024.0000,15.0489,202.2413,35.0600,202.6921,48,0\nread,2012.0224,2026.8185,0.0158,131072.0000,1024.0000,0.4558,3.0314,1.0307,3.0536,48,0\n")),(0,r.kt)("p",null,"Our write bandwidth is 30 MiB/s and our read bandwidth is 2012 MiB/s."),(0,r.kt)("h3",{id:"ior-with-hermes"},"IOR with Hermes"),(0,r.kt)("p",null,"To enable Hermes with an IOR checkpoint/restart workload, we must start a\ndaemon, ",(0,r.kt)("inlineCode",{parentName:"p"},"LD_PRELOAD")," a Hermes adapter and set some environment variables."),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},(0,r.kt)("strong",{parentName:"p"},"NOTE"),": As a temporary workaround to ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/HDFGroup/hermes/issues/258"},"issue #258")," we must\ncomment out the line ",(0,r.kt)("inlineCode",{parentName:"p"},"backend->close(fd, params->backend_options);")," in\n",(0,r.kt)("inlineCode",{parentName:"p"},"ior.c:TestIoSys")," before compiling IOR. This change is implemented in the ",(0,r.kt)("inlineCode",{parentName:"p"},"chogan/hermes")," branch of the IOR fork ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/ChristopherHogan/ior/tree/chogan/hermes"},"here"),".")),(0,r.kt)("p",null,"We spawn a daemon on each node, then run our app with the appropriate\nenvironment variables, similar to the process described above."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'HERMES_CONF_PATH=/absolute/path/to/hermes.yaml\n\n# Start one daemon on each node\nmpirun -n 4 -ppn 1 \\\n  -genv HERMES_CONF ${HERMES_CONF_PATH} \\\n  ${HERMES_INSTALL_DIR}/bin/hermes_daemon &\n\n# Give the daemons a chance to initialize\nsleep 3\n\n# Start "checkpoint" app\nmpirun -n 48 -ppn 12 \\\n  -genv LD_PRELOAD ${HERMES_INSTALL_DIR}/lib/libhermes_posix.so \\\n  -genv HERMES_CONF ${HERMES_CONF_PATH} \\\n  -genv HERMES_CLIENT 1 \\\n  -genv ADAPTER_MODE SCRATCH \\\n  -genv HERMES_STOP_DAEMON 0 \\\n  ior -w -k -o ${CHECKPOINT_FILE} -t 1m -b 128m -F -e -Y -O summaryFormat=CSV\n\n# Start the "restart" app\nmpirun -n 48 -ppn 8 \\\n  -genv LD_PRELOAD ${HERMES_INSTALL_DIR}/lib/libhermes_posix.so \\\n  -genv HERMES_CONF ${HERMES_CONF_PATH} \\\n  -genv HERMES_CLIENT 1 \\\n  -genv ADAPTER_MODE SCRATCH \\\n  ior -r -o ${CHECKPOINT_FILE} -t 1m -b 128m -F -e -O summaryFormat=CSV\n')),(0,r.kt)("p",null,"Results:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"access,bw(MiB/s),IOPS,Latency,block(KiB),xfer(KiB),open(s),wr/rd(s),close(s),total(s),numTasks,iter\nwrite,1748.0946,1928.3122,0.0122,131072,1024,1.9385,3.1862,0.8167,3.5147\nread,2580.2756,2861.2635,0.0074,131072,1024,0.1923,2.1473,1.7458,2.3811\n")),(0,r.kt)("p",null,"We get a nice boost in write bandwidth, and a modest speedup in read bandwidth,\nall with no code changes."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Checkpoint-Restart Results",src:n(8199).Z,width:"600",height:"371"})),(0,r.kt)("p",null,"We haven't done any performance optimization yet, so I expect to bridge the gap\nsignificantly between the 2.5 GiB read speed of Hermes and the baseline speed of\nreading from RAM (tmpfs on /dev/shm) with IOR of 60 GiB."))}h.isMDXComponent=!0},8199:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/IOR_Checkpoint_Restart-84001580a006c7d4ebf6025bfee0fa1f.png"}}]);