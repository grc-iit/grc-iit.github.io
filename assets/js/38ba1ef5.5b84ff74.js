"use strict";(self.webpackChunkgrc=self.webpackChunkgrc||[]).push([[2749],{796:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>r,metadata:()=>c,toc:()=>d});var a=i(5893),n=i(1151),s=i(3161);const r={title:"ACES: Accelerating Sparse Matrix Multiplication with Adaptive Execution Flow and Concurrency-Aware Cache Optimizations"},o="ACES: Accelerating Sparse Matrix Multiplication with Adaptive Execution Flow and Concurrency-Aware Cache Optimizations",c={type:"mdx",permalink:"/research/projects/aces",source:"@site/src/pages/research/projects/aces.mdx",title:"ACES: Accelerating Sparse Matrix Multiplication with Adaptive Execution Flow and Concurrency-Aware Cache Optimizations",description:"Background",frontMatter:{title:"ACES: Accelerating Sparse Matrix Multiplication with Adaptive Execution Flow and Concurrency-Aware Cache Optimizations"},unlisted:!1},l={},d=[{value:"Background",id:"background",level:2},{value:"Design",id:"design",level:2},{value:"Key Features",id:"key-features",level:2},{value:"Results",id:"results",level:2},{value:"Conclusion",id:"conclusion",level:2},{value:"Members",id:"members",level:2}];function u(e){const t={a:"a",h1:"h1",h2:"h2",li:"li",p:"p",strong:"strong",ul:"ul",...(0,n.a)(),...e.components},{FAIcon:r}=t;return r||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("FAIcon",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.h1,{id:"aces-accelerating-sparse-matrix-multiplication-with-adaptive-execution-flow-and-concurrency-aware-cache-optimizations",children:"ACES: Accelerating Sparse Matrix Multiplication with Adaptive Execution Flow and Concurrency-Aware Cache Optimizations"}),"\n",(0,a.jsx)(s.Z,{projectId:"aces"}),"\n",(0,a.jsx)(t.h2,{id:"background",children:"Background"}),"\n",(0,a.jsx)(t.p,{children:"As AI applications grow in complexity, they require hardware architectures capable of handling massive memory demands and complex computations.\nEfficient processing of sparse data structures, especially in sparse matrix operations, is essential in many AI and scientific computing tasks.\nHowever, traditional architectures often struggle with the data movement overhead and irregular memory access patterns inherent in these applications."}),"\n",(0,a.jsx)("p",{children:(0,a.jsx)("img",{src:i(918).Z,width:"800"})}),"\n",(0,a.jsx)(t.h2,{id:"design",children:"Design"}),"\n",(0,a.jsx)(t.p,{children:"The ACES accelerator addresses these challenges through a novel combination of adaptive execution flows and concurrency-aware memory optimizations,\nspecifically designed for Sparse Matrix-Matrix Multiplication. By optimizing both dataflow and memory management, ACES enhances the performance of\nsparse computations in AI, allowing efficient processing of data-intensive workloads."}),"\n",(0,a.jsx)("p",{children:(0,a.jsx)("img",{src:i(6715).Z,width:"800"})}),"\n",(0,a.jsx)(t.h2,{id:"key-features",children:"Key Features"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Adaptive Execution Flow"}),": Dynamically adjusts execution flows based on input sparsity patterns to optimize parallelism and data reuse."]}),"\n"]}),"\n",(0,a.jsx)("p",{children:(0,a.jsx)("img",{src:i(2922).Z,width:"800"})}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Balanced Data Reuse and Synchronization"}),": Balances memory access with parallel\nexecution to maximize data reuse and minimize synchronization overhead. - ",(0,a.jsx)(t.strong,{children:"Concurrency-Aware\nCache Management"}),": Employs the PureFiber cache replacement policy, considering reuse\ndistance and concurrent accesses to improve cache performance. - ",(0,a.jsx)(t.strong,{children:"Non-Blocking Buffer\nIntegration"}),": Uses a non-blocking buffer to handle cache misses without stalling\nthe pipeline, enhancing concurrency."]}),"\n"]}),"\n",(0,a.jsx)("p",{children:(0,a.jsx)("img",{src:i(3903).Z,width:"800"})}),"\n",(0,a.jsx)(t.h2,{id:"results",children:"Results"}),"\n",(0,a.jsx)(t.p,{children:"ACES achieves substantial improvements over traditional architectures, demonstrating significant performance gains in AI workloads that\nrely on sparse matrix computations. Experimental results show up to a 2.1\xd7 speedup."}),"\n",(0,a.jsx)("p",{children:(0,a.jsx)("img",{src:i(2566).Z,width:"800"})}),"\n",(0,a.jsx)(t.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,a.jsx)(t.p,{children:"By integrating advanced dataflow and concurrency-aware memory optimizations, ACES provides a high-performance, scalable solution for\nhandling the demands of modern AI applications. These innovations contribute to the overall efficiency and scalability of AI hardware,\npositioning ACES as a foundational component in the future of AI computing."}),"\n",(0,a.jsx)(t.h2,{id:"members",children:"Members"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.a,{href:"https://xiaoyang-lu.github.io/",children:"Dr. Xiaoyang Lu"}),", Illinois Institute of Technology (",(0,a.jsxs)(t.a,{href:"mailto:xlu40@iit.edu",children:[(0,a.jsx)(r,{icon:"fa-solid fa-envelope"})," Contact"]}),")"]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.a,{href:"https://www.iit.edu/directory/people/xian-he-sun",children:"Dr. Xian-He Sun"}),", Illinois Institute of Technology (",(0,a.jsxs)(t.a,{href:"mailto:sun@iit.edu",children:[(0,a.jsx)(r,{icon:"fa-solid fa-envelope"})," Contact"]}),")"]}),"\n"]})]})}function p(e={}){const{wrapper:t}={...(0,n.a)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(u,{...e})}):u(e)}},3161:(e,t,i)=>{i.d(t,{Z:()=>r});i(7294);var a=i(512),n=i(866),s=i(5893);function r(e){let{addMargin:t=!0,projectId:i}=e;const{isOpenSource:r=!1,isOurs:o=!1,type:c}=(0,n.R)(i),l="funded"===c;return l||r||o?(0,s.jsxs)("div",{className:(0,a.Z)(t&&"margin-bottom--md"),style:{lineHeight:1},children:[o&&(0,s.jsx)("span",{className:"badge badge--primary margin-horiz--xs",children:"GRC-LED"}),l&&(0,s.jsx)("span",{className:"badge badge--success margin-horiz--xs",children:"FUNDED"}),r&&(0,s.jsx)("span",{className:"badge badge--secondary margin-horiz--xs",children:"OPEN SOURCE"})]}):null}},866:(e,t,i)=>{i.d(t,{R:()=>s,Z:()=>n});const a=[{id:"aces",name:"ACES",title:"ACES: Accelerating Sparse Matrix Multiplication with Adaptive Execution Flow and Concurrency-Aware Cache Optimizations",shortDescription:"ACES accelerates sparse matrix multiplications by dynamically adjusting execution flows and using concurrency-aware cache management to reduce data movement and optimize performance.",link:"/research/projects/aces",isFeatured:!1,isOpenSource:!1,isOurs:!0,researchStatus:"ready",status:"active",type:"funded"},{id:"coeus",name:"Coeus",title:"Coeus: Accelerating Scientific Insights Using Enriched Metadata",shortDescription:"In collaboration with Sandia and Oak Ridge National Laboratories, coeus investigate the use of an active storage system to calculate derived quantities and support complex queries on scientific data (simulation and observational) as well as optimizing data placement across the storage hierarchy, with awareness of the resource limitations, to better support the scientific discovery process.",link:"/research/projects/coeus",isFeatured:!0,isOurs:!0,researchStatus:"r&d",status:"active",type:"funded"},{id:"chrome",name:"CHROME",title:"CHROME: Concurrency-Aware Holistic Cache Management Framework with Online Reinforcement Learning",shortDescription:"CHROME improves cache management through a concurrency-aware framework that integrates cache replacement, bypassing, and prefetching using online reinforcement learning. This holistic approach dynamically optimizes cache decisions, adapting to workload changes and enhancing cache efficiency across multi-core systems.",link:"/research/projects/chrome",isFeatured:!1,isOpenSource:!0,isOurs:!0,researchStatus:"ready",status:"active",type:"funded"},{id:"chronolog",name:"ChronoLog",title:"ChronoLog: A High-Performance Storage Infrastructure for Activity and Log Workloads",shortDescription:"HPC applications generate more data than storage systems can handle, and it is becoming increasingly important to store activity (log) data generated by people and applications. ChronoLog is a hierarchical, distributed log store that leverages physical time to achieve log ordering and reduce contention while utilizing storage tiers to elastically scale the log capacity.",link:"/research/projects/chronolog",isFeatured:!0,isOpenSource:!0,isOurs:!0,researchStatus:"testing",status:"active",type:"funded"},{id:"iris",name:"IRIS",title:"IRIS: I/O Redirection Via Integrated Storage",shortDescription:"Various storage solutions exist and require specialized APIs and data models in order to use, which binds developers, applications, and entire computing facilities to using certain interfaces. Each storage system is designed and optimized for certain applications but does not perform well for others. IRIS is a unified storage access system that bridges the semantic gap between filesystems and object stores.",link:"/research/projects/iris",isFeatured:!1,isOpenSource:!0,isOurs:!0,researchStatus:"testing",status:"active",type:"funded"},{id:"hermes",name:"Hermes",title:"Hermes: Extending the HDF Library to Support Intelligent I/O Buffering for Deep Memory and Storage Hierarchy System",shortDescription:"To reduce the I/O bottleneck, complex storage hierarchies have been introduced. However, managing this complexity should not be left to application developers. Hermes is a middeware library that automatically manages buffering in heterogeneous storage environments.",link:"/research/projects/hermes",isFeatured:!0,isOpenSource:!0,isOurs:!0,researchStatus:"ready",status:"active",type:"funded"},{id:"labios",name:"Labios",title:"LABIOS: A Distributed Label-Based I/O System",shortDescription:"HPC and Big Data environments have diverged over the years, resulting in diverging and even conflicting I/O requirements. Labios aims to address the challenges vital to HPC + Big Data Convergence",link:"/research/projects/labios",isFeatured:!1,isOurs:!0,researchStatus:"r&d",status:"active",type:"funded"},{id:"dtio",name:"DTIO",title:"DTIO: A Data Task I/O Runtime",shortDescription:"In partnership with Argonne National Laboratory, DTIO investigates the use of a task framework for unifying complex I/O stacks and providing features such as resilience, fault-tolerance, and task replay.",link:"/research/projects/dtio",isFeatured:!1,isOurs:!0,researchStatus:"testing",status:"active",type:"funded"},{id:"viper",name:"Viper",title:"Viper: A High-Performance I/O Framework for Transferring Deep Neural Network Models",shortDescription:"Within a DL workflow, exchanging DNN models through PFS may result in  high model update latency and discovery latency. Moreover, model update frequency affects both training and inference performance. Viper is an I/O framework aiming to accelerate model discovery and delivery, and to find an optimal model checkpoint schedule to balance the trade-off.",link:"/research/projects/viper",isFeatured:!1,isOurs:!0,researchStatus:"r&d",status:"active",type:"funded"},{id:"dayu",name:"DaYu",title:"DaYu: Optimizing Distributed Scientific Workflows by Decoding Dataflow Semantics and Dynamics",shortDescription:"Nowadays, distributed scientific workflows encounter challenges in data movement through storage systems. DaYu, by capturing the mapping of data objects to I/O operations, can uncover new insights for optimizing workflow data movement.",link:"/research/projects/dayu",isFeatured:!1,isOpenSource:!0,isOurs:!0,researchStatus:"ready",status:"active",type:"funded"},{id:"wisio",name:"WisIO",title:"WisIO: Automated I/O Bottleneck Detection via Multi-Perspective Views for HPC Workloads",shortDescription:"Explore WisIO, an automated I/O bottleneck detection tool with multi-perspective views for I/O trace data analysis. Overcoming large-scale I/O challenges, WisIO utilizes distributed computing and an extensible rule engine for tailored solutions. Elevate your I/O analysis in HPC environments with WisIO.",link:"/research/projects/wisio",isFeatured:!1,isOpenSource:!1,isOurs:!0,researchStatus:"r&d",status:"active",type:"student"},{id:"storehub",name:"StoreHub",title:"StoreHub",shortDescription:"StoreHub is a collaborative platform designed to advance data storage research by providing a specialized infrastructure that meets the unique needs of researchers. It brings together experts handling large amounts of data, focusing on I/O performance, and developing innovative storage solutions, making it a vital resource for the community.",link:"/research/projects/storehub",isFeatured:!1,isOpenSource:!1,isOurs:!0,researchStatus:"r&d",status:"active",type:"funded"}],n=a;function s(e){return a.find((t=>t.id===e))}},3903:(e,t,i)=>{i.d(t,{Z:()=>a});const a=i.p+"assets/images/ACES_NBbuffer-058ac36aa8bec292e822ba2f9b1a43c6.png"},918:(e,t,i)=>{i.d(t,{Z:()=>a});const a=i.p+"assets/images/ACES_background-b0f0defc4c4a31038847f369ac2cfd5e.png"},2922:(e,t,i)=>{i.d(t,{Z:()=>a});const a=i.p+"assets/images/ACES_flow-08b21c1fd8c53c03ae2b8bc8c417f802.png"},6715:(e,t,i)=>{i.d(t,{Z:()=>a});const a=i.p+"assets/images/ACES_overview-f1bffff363e3c0ec597cd78b24b8612e.png"},2566:(e,t,i)=>{i.d(t,{Z:()=>a});const a=i.p+"assets/images/ACES_result-8964c07d38931849b59c2f070ec493ca.png"},1151:(e,t,i)=>{i.d(t,{Z:()=>o,a:()=>r});var a=i(7294);const n={},s=a.createContext(n);function r(e){const t=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),a.createElement(s.Provider,{value:t},e.children)}}}]);