"use strict";(self.webpackChunkgrc=self.webpackChunkgrc||[]).push([[31319],{47188:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>t,contentTitle:()=>o,default:()=>p,frontMatter:()=>c,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"hpc-tutorials/cpp-introduction/mpi","title":"Intro to MPI","description":"MPI (Message Passing Interface) is a standardized and portable message-passing system designed for parallel computing. It enables communication between processes in distributed memory systems, making it essential for High-Performance Computing (HPC) applications.","source":"@site/docs/02-hpc-tutorials/04-cpp-introduction/13-mpi.mdx","sourceDirName":"02-hpc-tutorials/04-cpp-introduction","slug":"/hpc-tutorials/cpp-introduction/mpi","permalink":"/docs/hpc-tutorials/cpp-introduction/mpi","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":13,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Unit Testing in C++","permalink":"/docs/hpc-tutorials/cpp-introduction/unit-tests"},"next":{"title":"Docker Guide","permalink":"/docs/hpc-tutorials/docker/docker-basics"}}');var r=s(74848),a=s(28453);const c={},o="Intro to MPI",t={},l=[{value:"Linking to MPI in CMake",id:"linking-to-mpi-in-cmake",level:2},{value:"Ranks + Communicators",id:"ranks--communicators",level:2},{value:"Barrier",id:"barrier",level:2},{value:"Reduction",id:"reduction",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"intro-to-mpi",children:"Intro to MPI"})}),"\n",(0,r.jsx)(n.p,{children:"MPI (Message Passing Interface) is a standardized and portable message-passing system designed for parallel computing. It enables communication between processes in distributed memory systems, making it essential for High-Performance Computing (HPC) applications."}),"\n",(0,r.jsx)(n.p,{children:"Key features of MPI include:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Process-based parallelism"}),"\n",(0,r.jsx)(n.li,{children:"Point-to-point communication"}),"\n",(0,r.jsx)(n.li,{children:"Collective operations"}),"\n",(0,r.jsx)(n.li,{children:"Support for both SPMD and MPMD programming models"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"MPI is widely used in scientific computing, engineering simulations, and data analysis across HPC clusters. While it requires explicit management of parallelism, it offers excellent performance and scalability."}),"\n",(0,r.jsx)(n.p,{children:"Common MPI implementations:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"OpenMPI"}),"\n",(0,r.jsx)(n.li,{children:"MPICH"}),"\n",(0,r.jsx)(n.li,{children:"Intel MPI"}),"\n",(0,r.jsx)(n.li,{children:"Microsoft MPI"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"linking-to-mpi-in-cmake",children:"Linking to MPI in CMake"}),"\n",(0,r.jsxs)(n.p,{children:["To link with MPI in CMake, add the following to your ",(0,r.jsx)(n.code,{children:"CMakeLists.txt"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cmake",children:"find_package(MPI REQUIRED)\nadd_executable(your_program main.cpp)\ntarget_link_libraries(your_program PRIVATE MPI::MPI_CXX)\n"})}),"\n",(0,r.jsx)(n.p,{children:"This will:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Find MPI installation on your system"}),"\n",(0,r.jsx)(n.li,{children:"Create your executable"}),"\n",(0,r.jsx)(n.li,{children:"Link MPI libraries to your program"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"ranks--communicators",children:"Ranks + Communicators"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:'#include <mpi.h>\n#include <iostream>\n\nint main(int argc, char** argv) {\n    MPI_Init(&argc, &argv);\n\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    std::cout << "Process " << rank << " of " << size << std::endl;\n\n    MPI_Finalize();\n    return 0;\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:"To compile and run:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"mpic++ mpi_example.cpp -o mpi_example\nmpirun -np 4 ./mpi_example\n"})}),"\n",(0,r.jsx)(n.p,{children:"The output of this should be"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"Process 0 of 4\nProcess 1 of 4\nProcess 2 of 4\nProcess 3 of 4\n"})}),"\n",(0,r.jsxs)(n.p,{children:["In MPI, a ",(0,r.jsx)(n.strong,{children:"rank"})," is a unique identifier assigned to each process in a parallel program. Ranks are integers starting from 0, allowing processes to identify themselves and determine their specific roles in the program."]}),"\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.strong,{children:"communicator"})," is a context that defines a group of processes that can communicate with each other. The most common communicator is ",(0,r.jsx)(n.code,{children:"MPI_COMM_WORLD"}),", which includes all processes in the application. Communicators enable:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Process organization"}),"\n",(0,r.jsx)(n.li,{children:"Safe message passing"}),"\n",(0,r.jsx)(n.li,{children:"Collective operations across specific process groups"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"barrier",children:"Barrier"}),"\n",(0,r.jsx)(n.p,{children:"A barrier is a synchronization point where all processes must arrive before any can proceed. Here's an example:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:'#include <mpi.h>\n#include <iostream>\n#include <unistd.h>\n\nint main(int argc, char** argv) {\n    MPI_Init(&argc, &argv);\n\n    int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    // Simulate work with sleep\n    sleep(rank);\n    std::cout << "Process " << rank << " reached barrier" << std::endl;\n\n    // Wait for all processes\n    MPI_Barrier(MPI_COMM_WORLD);\n\n    std::cout << "Process " << rank << " passed barrier" << std::endl;\n\n    MPI_Finalize();\n    return 0;\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:"To compile and run:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"mpic++ mpi_barrier.cpp -o mpi_barrier\nmpirun -np 4 ./mpi_barrier\n"})}),"\n",(0,r.jsx)(n.p,{children:"Example output:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"Process 0 reached barrier\nProcess 1 reached barrier\nProcess 2 reached barrier\nProcess 3 reached barrier\nProcess 0 passed barrier\nProcess 1 passed barrier\nProcess 2 passed barrier\nProcess 3 passed barrier\n"})}),"\n",(0,r.jsx)(n.h2,{id:"reduction",children:"Reduction"}),"\n",(0,r.jsx)(n.p,{children:"Below is an example of using MPI to calculate the maximum value across processes and then print in the first:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-cpp",children:'#include <mpi.h>\n#include <iostream>\n\nint main(int argc, char** argv) {\n    MPI_Init(&argc, &argv);\n\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    // Use rank as the local value\n    int local_value = rank;\n\n    std::cout << "Process " << rank << " has value: " << local_value << std::endl;\n\n    // Find the maximum value across all processes\n    int global_max;\n    MPI_Reduce(&local_value, &global_max, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n    // Only the root process (rank 0) prints the result\n    if (rank == 0) {\n        std::cout << "Maximum value across all processes: " << global_max << std::endl;\n    }\n\n    MPI_Finalize();\n    return 0;\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:"To compile and run:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"mpic++ mpi_reduction.cpp -o mpi_reduction\nmpirun -np 4 ./mpi_reduction\n"})}),"\n",(0,r.jsx)(n.p,{children:"Example output:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"Process 0 has value: 0\nProcess 1 has value: 1\nProcess 2 has value: 2\nProcess 3 has value: 3\nMaximum value across all processes: 3\n"})})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},28453:(e,n,s)=>{s.d(n,{R:()=>c,x:()=>o});var i=s(96540);const r={},a=i.createContext(r);function c(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:c(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);