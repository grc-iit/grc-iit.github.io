"use strict";(self.webpackChunkgrc=self.webpackChunkgrc||[]).push([[15880],{69281:e=>{e.exports=JSON.parse('{"abstract":"Data swapping between CPUs and GPUs is widely used to address the GPU memory shortage issue when training deep\\nneural networks (DNNs) requiring a larger amount of memory than that a GPU may have. Data swapping may become a bottleneck\\nwhen its latency is longer than the latency of DNN computations. Tensor compression in GPUs can reduce the data swapping time.\\nHowever, existing works on compressing tensors in the virtual memory of GPUs have three major issues: lack of portability because\\nits implementation requires additional (de)compression units in memory controllers, sub-optimal compression performance for varying\\ntensor compression ratios and sizes, and poor adaptation to dense tensors because they only focus on sparse tensors. We propose a\\nself-tuning tensor compression framework, named CSWAP+, for improving the virtual memory management of GPUs. It uses GPUs for\\n(de)compression directly and thus has high portability and is minimally dependent on GPU architecture features. Furthermore, it only\\napplies compression on tensors that are deemed to be cost-effective considering their compression ratio, size, and the characteristics\\nof compression algorithms at runtime. Finally, to adapt to DNN models with dense tensors, it also supports cost-effective lossy\\ncompression for dense tensors with nearly no model training accuracy degradation. We conduct the experiments through six\\nrepresentative memory-intensive DNN models. Compared to vDNN, CSWAP+ reduces tensor swapping latency by up to 50.9%\\nand 46.1% with NVIDIA V100 GPU, for DNN models with sparse and dense tensors, respectively.","authors":["P. Chen","S. He","X. Zhang","S. Chen","P. Hong","Y. Yin","X.-H. Sun"],"date":"December, 2022","doi":"10.1109/tpds.2022.3193867","links":{"bibtex":"http://cs.iit.edu/~scs/assets/files/chen2022accelerating.bib","citation":"http://cs.iit.edu/~scs/assets/files/chen2022accelerating.txt","pdf":"http://cs.iit.edu/~scs/assets/files/chen2022accelerating.pdf"},"month":12,"slug":"chen-2022-accelerating-tensor-ba35","tags":["DNN","GPU","Tensor","Swapping","Compression"],"title":"Accelerating Tensor Swapping in GPUs with Self-Tuning Compression","type":"Journal","venue":"Transactions on Parallel and Distributed Systems (TPDS\'22)","year":2022}')}}]);