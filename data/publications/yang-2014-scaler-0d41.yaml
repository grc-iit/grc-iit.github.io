abstract: |-
  Two camps of file systems exist: parallel file systems
  designed for conventional high performance computing (HPC)
  and distributed file systems designed for newly emerged data-
  intensive applications. Addressing the big data challenge requires
  an approach that utilizes both high performance computing and
  data-intensive computing power. Thus, HPC applications may
  need to interact with distributed file systems, such as HDFS. The
  N-1 (N-to-1) parallel file write is a critical technical challenge,
  because it is very common for HPC applications but HDFS does
  not allow it. This study introduces a system solution, named
  SCALER, which allows MPI based applications to directly access
  HDFS without extra data movement. SCALER supports N-1
  file write at both the inter-block level and intra-block level.
  Experimental results confirm that SCALER achieves the design
  goal efficiently.
authors:
  - X. Yang
  - Y. Yin
  - H. Jin
  - X.-H. Sun
date: September, 2014
doi: 10.1109/cluster.2014.6968736
links:
  bibtex: http://cs.iit.edu/~scs/assets/files/yang2014scaler.bib
  citation: http://cs.iit.edu/~scs/assets/files/yang2014scaler.txt
  pdf: http://cs.iit.edu/~scs/assets/files/SCALER_xyang.pdf
month: 9
slug: yang-2014-scaler-0d41
tags: []
title: 'SCALER: Scalable Parallel File Write in HDFS'
type: Conference
venue: International Conference on Cluster Computing 2014 (Cluster'14), Madrid, Spain
year: 2014
