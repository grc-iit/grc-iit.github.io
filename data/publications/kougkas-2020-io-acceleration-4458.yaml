abstract: >-
  Modern High-Performance Computing (HPC) systems are adding extra layers to the
  memory and storage

  hierarchy, named deep memory and storage hierarchy (DMSH), to increase I/O
  performance. New hardware technologies,

  such as NVMe and SSD, have been introduced in burst buffer installations to
  reduce the pressure for external storage and

  boost the burstiness of modern I/O systems. The DMSH has demonstrated its
  strength and potential in practice. However,

  each layer of DMSH is an independent heterogeneous system and data movement
  among more layers is significantly more

  complex even without considering heterogeneity. How to efficiently utilize the
  DMSH is a subject of research facing the HPC

  community. Further, accessing data with a high-throughput and low-latency is
  more imperative than ever. Data prefetching

  is a well-known technique for hiding read latency by requesting data before it
  is needed to move it from a high-latency medium

  (e.g., disk) to a low-latency one (e.g., main memory). However, existing
  solutions do not consider the new deep memory and

  storage hierarchy and also suffer from under-utilization of prefetching
  resources and unnecessary evictions. Additionally,

  existing approaches implement a client-pull model where understanding the
  application's I/O behavior drives prefetching

  decisions. Moving towards exascale, where machines run multiple applications
  concurrently by accessing files in a workflow, a

  more data-centric approach resolves challenges such as cache pollution and
  redundancy. In this paper, we present the design

  and implementation of Hermes: a new, heterogeneous-aware, multi-tiered,
  dynamic, and distributed I/O buffering system.

  Hermes enables, manages, supervises, and, in some sense, extends I/O buffering
  to fully integrate into the DMSH. We

  introduce three novel data placement policies to efficiently utilize all
  layers and we present three novel techniques to perform

  memory, metadata, and communication management in hierarchical buffering
  systems. Additionally, we demonstrate the

  benefits of a truly hierarchical data prefetcher that adopts a server-push
  approach to data prefetching. Our evaluation

  shows that, in addition to automatic data movement through the hierarchy,
  Hermes can significantly accelerate I/O and

  outperforms by more than 2x state-of-the-art buffering platforms. Lastly,
  results show 10%-35% performance gains over

  existing prefetchers and over 50% when compared to systems with no
  prefetching.
authors:
  - A. Kougkas
  - H. Devarajan
  - X.-H. Sun
date: January, 2020
doi: 10.1007/s11390-020-9781-1
links:
  bibtex: http://cs.iit.edu/~scs/assets/files/IOaccel.bib
  citation: http://cs.iit.edu/~scs/assets/files/IOaccel.txt
  pdf: http://cs.iit.edu/~scs/assets/files/IOaccel.pdf
month: 1
slug: kougkas-2020-io-acceleration-4458
tags:
  - I/O Buffering
  - Heterogeneous Buffering
  - Layered Buffering
  - Deep Memory Hierarchy
  - Burst Buffers
  - Hierarchical Data Prefetching
  - Data-Centric Architecture
  - Hermes
title: I/O Acceleration via Multi-Tiered Data Buffering and Prefetching
type: Journal
venue: Journal of Computer Science and Technology (JCST'20), vol 35. no 1. pp 92-120
year: 2020
